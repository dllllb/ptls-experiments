{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faedbc3f",
   "metadata": {},
   "source": [
    "# <font size=\"7\">Libs</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "790dd034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version (<2):  1.12.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "print('torch version (<2): ', torch.__version__)\n",
    "\n",
    "import ptls\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.frames.coles import losses, sampling_strategies\n",
    "from ptls.frames.coles import split_strategy\n",
    "\n",
    "from ptls.frames.inference_module import InferenceModule\n",
    "\n",
    "from ptls.nn.seq_encoder import agg_feature_seq_encoder\n",
    "from ptls.nn import RnnSeqEncoder, TrxEncoder, Head\n",
    "from ptls.nn.seq_encoder.agg_feature_seq_encoder import AggFeatureSeqEncoder\n",
    "\n",
    "from ptls.data_load.datasets import AugmentationDataset, MemoryMapDataset\n",
    "from ptls.data_load.augmentations import AllTimeShuffle, DropoutTrx\n",
    "from ptls.data_load.datasets.parquet_dataset import ParquetDataset\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter, FeatureFilter\n",
    "from ptls.data_load.datasets import parquet_file_scan\n",
    "from ptls.data_load.datasets import ParquetDataset, ParquetFiles, AugmentationDataset\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter, FeatureFilter\n",
    "from ptls.data_load.augmentations import DropoutTrx\n",
    "from ptls.data_load.datasets import inference_data_loader\n",
    "from ptls.data_load.utils import collate_feature_dict\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "import seaborn as sns\n",
    "# import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "617918e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('default')\n",
    "sns.set(rc={'figure.figsize':(8, 6)})\n",
    "sns.set_style('white')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018e671b",
   "metadata": {},
   "source": [
    "# <font size=\"5\">Data Module</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "284ecb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = OmegaConf.load('src/ptls-experiments/scenario_rosbank/conf/mles_params.yaml')\n",
    "\n",
    "module_conf = conf['data_module']\n",
    "\n",
    "data_conf = OmegaConf.load('src/ptls-experiments/scenario_rosbank/conf/dataset_unsupervised/parquet.yaml')\n",
    "\n",
    "data_conf['train']['data']['data']['data_files']['file_path'] = 'src/ptls-experiments/scenario_rosbank/data/train_trx.parquet'\n",
    "data_conf['valid']['data']['data_files']['file_path'] = 'src/ptls-experiments/scenario_rosbank/data/train_trx.parquet'\n",
    "\n",
    "module_conf['train_data']['data'] = data_conf['train']\n",
    "module_conf['valid_data']['data'] = data_conf['valid']\n",
    "\n",
    "data_module = hydra.utils.instantiate(module_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3586094",
   "metadata": {},
   "source": [
    "# <font size=\"7\">Model</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a82d5e5",
   "metadata": {},
   "source": [
    "# <font size=\"6\">Loss Block</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "729545f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class L2NormEncoder(nn.Module):\n",
    "    def __init__(self, eps=1e-9):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return x / (x.pow(2).sum(dim=-1, keepdim=True) + self.eps).pow(0.5)\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, margin, sampling_strategy):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.pair_selector = sampling_strategy\n",
    "        \n",
    "        self.norm = L2NormEncoder()\n",
    "        \n",
    "    def forward(self, embeddings, target):\n",
    "        embeddings = self.norm(embeddings)\n",
    "        \n",
    "        positive_pairs, negative_pairs = self.pair_selector.get_pairs(embeddings, target)\n",
    "        positive_loss = F.pairwise_distance(embeddings[positive_pairs[:, 0]], embeddings[positive_pairs[:, 1]]).pow(2)\n",
    "        negative_loss = F.relu(\n",
    "            self.margin - F.pairwise_distance(embeddings[negative_pairs[:, 0]], embeddings[negative_pairs[:, 1]])\n",
    "        ).pow(2)\n",
    "        loss = torch.cat([positive_loss, negative_loss], dim=0)\n",
    "        \n",
    "        return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57d24b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VICRegLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        super(VICRegLoss, self).__init__()\n",
    "        \n",
    "        self._agg_encoder = AggFeatureSeqEncoder(         \n",
    "            embeddings={\n",
    "                \"mcc\": {\"in\": 100},\n",
    "                \"channel_type\": {\"in\": 4},\n",
    "                \"currency\": {\"in\": 4},\n",
    "                \"trx_category\": {\"in\": 10}\n",
    "            },\n",
    "\n",
    "            numeric_values={\n",
    "                'amount': 'identity',\n",
    "            },\n",
    "     \n",
    "            was_logified=True,\n",
    "            log_scale_factor=1\n",
    "        )\n",
    "        self.instanceNormAggs = nn.InstanceNorm1d(362, affine=True)\n",
    "\n",
    "        self.norm = L2NormEncoder()\n",
    "        \n",
    "    def forward(self, embeddings, aggs):\n",
    "        aggs = self._agg_encoder(aggs)\n",
    "        aggs = self.norm(aggs.T)\n",
    "        \n",
    "        cov_aggs_embs = (aggs @ embeddings) / embeddings.shape[0]\n",
    "        cov_loss = cov_aggs_embs.pow_(2).sum()\n",
    "        \n",
    "        std_embeddings = torch.sqrt(embeddings.var(dim=0) + 0.0001)\n",
    "        std_loss = torch.mean(F.relu(1 - std_embeddings))\n",
    "        \n",
    "        return (cov_loss, std_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a32474b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self, contrastiveLoss, vicregLoss):\n",
    "        super(Loss, self).__init__()\n",
    "        \n",
    "        self.contrastiveLoss = contrastiveLoss\n",
    "        self.vicregLoss = vicregLoss\n",
    "        \n",
    "    def forward(self, embeddings, target, aggs):\n",
    "        \n",
    "        (cov_loss, std_loss) = self.vicregLoss(embeddings, aggs)\n",
    "        con_loss = self.contrastiveLoss.forward(embeddings, target)\n",
    "        \n",
    "        return ((con_loss, cov_loss, std_loss), 0.55 * con_loss + 1 * cov_loss + 1 * std_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfac9033",
   "metadata": {},
   "source": [
    "# <font size=\"6\">ABS Module</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c701c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from ptls.data_load.padded_batch import PaddedBatch\n",
    "\n",
    "\n",
    "class ABSModule(pl.LightningModule):\n",
    "    @property\n",
    "    def metric_name(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @property\n",
    "    def is_requires_reduced_sequence(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def shared_step(self, x, y):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            x:\n",
    "            y:\n",
    "\n",
    "        Returns: y_h, y\n",
    "\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __init__(self, validation_metric=None,\n",
    "                       seq_encoder=None,\n",
    "                       loss=None,\n",
    "                       optimizer_partial=None,\n",
    "                       lr_scheduler_partial=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        params : dict\n",
    "            params for creating an encoder\n",
    "        seq_encoder : torch.nn.Module\n",
    "            sequence encoder, if not provided, will be constructed from params\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # self.save_hyperparameters()\n",
    "\n",
    "        self._loss = loss\n",
    "        self._seq_encoder = seq_encoder\n",
    "        self._seq_encoder.is_reduce_sequence = self.is_requires_reduced_sequence\n",
    "        self._validation_metric = validation_metric\n",
    "\n",
    "        self._optimizer_partial = optimizer_partial\n",
    "        self._lr_scheduler_partial = lr_scheduler_partial\n",
    "        \n",
    "    @property\n",
    "    def seq_encoder(self):\n",
    "        return self._seq_encoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._seq_encoder(x)\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        \n",
    "        y_h, y = self.shared_step(*batch)\n",
    "        \n",
    "        (con_loss, cov_loss, std_loss), loss = self._loss(y_h, y, batch[0])\n",
    "\n",
    "        self.log('con_loss', con_loss)\n",
    "        self.log('cov_loss', cov_loss)\n",
    "        self.log('std_loss', std_loss)\n",
    "        self.log('loss', loss)\n",
    "        \n",
    "        if type(batch) is tuple:\n",
    "            x, y = batch\n",
    "            if isinstance(x, PaddedBatch):\n",
    "                self.log('seq_len', x.seq_lens.float().mean(), prog_bar=True)\n",
    "        else:\n",
    "            # this code should not be reached\n",
    "            self.log('seq_len', -1, prog_bar=True)\n",
    "            raise AssertionError('batch is not a tuple')\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        y_h, y = self.shared_step(*batch)\n",
    "        self._validation_metric(y_h, y)\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        self.log(self.metric_name, self._validation_metric.compute(), prog_bar=True)\n",
    "        self._validation_metric.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self._optimizer_partial(self.parameters())\n",
    "        scheduler = self._lr_scheduler_partial(optimizer)\n",
    "        \n",
    "        if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler = {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': self.metric_name,\n",
    "            }\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61c70fa",
   "metadata": {},
   "source": [
    "# <font size=\"6\">CoLES Module</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d081922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.frames.coles.metric import BatchRecallTopK\n",
    "from ptls.frames.coles.sampling_strategies import HardNegativePairSelector\n",
    "from ptls.nn.head import Head\n",
    "from ptls.nn.seq_encoder.containers import SeqEncoderContainer\n",
    "\n",
    "\n",
    "class CoLESModule(ABSModule):\n",
    "    def __init__(self,\n",
    "                 seq_encoder: SeqEncoderContainer = None,\n",
    "                 head=None,\n",
    "                 loss=None,\n",
    "                 validation_metric=None,\n",
    "                 optimizer_partial=None,\n",
    "                 lr_scheduler_partial=None):\n",
    "\n",
    "        if head is None:\n",
    "            head = Head(use_norm_encoder=True)\n",
    "\n",
    "        if loss is None:\n",
    "            loss = ContrastiveLoss(margin=0.5,\n",
    "                                   sampling_strategy=HardNegativePairSelector(neg_count=5))\n",
    "\n",
    "        if validation_metric is None:\n",
    "            validation_metric = BatchRecallTopK(K=4, metric='cosine')\n",
    "\n",
    "        super().__init__(validation_metric,\n",
    "                         seq_encoder,\n",
    "                         loss,\n",
    "                         optimizer_partial,\n",
    "                         lr_scheduler_partial\n",
    "                        )\n",
    "\n",
    "        self._head = head\n",
    "    @property\n",
    "    def metric_name(self):\n",
    "        return 'recall_top_k'\n",
    "\n",
    "    @property\n",
    "    def is_requires_reduced_sequence(self):\n",
    "        return True\n",
    "\n",
    "    def shared_step(self, x, y):\n",
    "        \n",
    "        y_h = self(x)\n",
    "        if self._head is not None:\n",
    "            y_h = self._head(y_h)\n",
    "        return y_h, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d093178",
   "metadata": {},
   "source": [
    "# <font size=\"6\">Model</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df891556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CoLESModule(\n",
    "      validation_metric=ptls.frames.coles.metric.BatchRecallTopK(K=4,\n",
    "                                                                 metric=\"cosine\"),\n",
    "      seq_encoder=RnnSeqEncoder(\n",
    "            trx_encoder=TrxEncoder(\n",
    "            use_batch_norm_with_lens=True,\n",
    "            norm_embeddings=False,\n",
    "            embeddings_noise=0.0003,\n",
    "            \n",
    "            embeddings={\n",
    "                \"mcc\": {\"in\": 100, \"out\": 24},\n",
    "                \"channel_type\": {\"in\": 4, \"out\": 4},\n",
    "                \"currency\": {\"in\": 4, \"out\": 4},\n",
    "                \"trx_category\": {\"in\": 10, \"out\": 4}\n",
    "            },\n",
    "\n",
    "            numeric_values={\n",
    "                'amount': 'identity',\n",
    "            }\n",
    "                \n",
    "            ),\n",
    "            type=\"lstm\",\n",
    "            hidden_size=1024,\n",
    "            bidir=False,\n",
    "            trainable_starter=\"static\",\n",
    "      ),\n",
    "     \n",
    "      head=Head(\n",
    "            use_norm_encoder=False,\n",
    "            input_size=1024,\n",
    "      ),\n",
    "        \n",
    "      loss=Loss(\n",
    "          ContrastiveLoss(\n",
    "            margin=0.5,\n",
    "            sampling_strategy=sampling_strategies.HardNegativePairSelector(neg_count=5),\n",
    "          ),\n",
    "          VICRegLoss()\n",
    "      ),\n",
    "    \n",
    "      optimizer_partial=partial(\n",
    "            torch.optim.Adam, \n",
    "            lr=0.004,\n",
    "            weight_decay=0.0\n",
    "      ),\n",
    "    \n",
    "      lr_scheduler_partial=partial(\n",
    "            torch.optim.lr_scheduler.StepLR,\n",
    "            step_size=10,\n",
    "            gamma=0.9025\n",
    "      ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "398cf440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type            | Params\n",
      "-------------------------------------------------------\n",
      "0 | _loss              | Loss            | 724   \n",
      "1 | _seq_encoder       | RnnSeqEncoder   | 4.4 M \n",
      "2 | _validation_metric | BatchRecallTopK | 0     \n",
      "3 | _head              | Head            | 0     \n",
      "-------------------------------------------------------\n",
      "4.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 M     Total params\n",
      "17.433    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcf2b034d504995bd2cb8669495b0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece1fedfd9324c828e05982f1927bb2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538e5dad52724c6ca4820e3a54412d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff67cad25dd04ac49555f4b6d7844d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aff1c3d83514572bafbb3526792055c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1797317156a0402cbb434af2e82cd3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6306828a39e849a5b82bdfe797a7cb83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2ab0447ddd4e739cc4dc2ee63815c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54470f6edff47f4af6d807ef37f7442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5237e95ff1e4418dbdf7429cdf2d289f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9dab212bc748dba236327dc157dba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4efdb84a6894e4f83b9dca68a7c9340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fbe4094d9345259c906c28477281cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2ed3064c1a48cfb5b451569a0f725c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb7293176a8490b975cb3598ce734a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeda1caf24a642d583711f32dcf585c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cddbc3b4a3c4b1bb52a2f4122468ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564ac8f25ab747d1898b3942c1f37a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decf21125a9c4f84a709edd5626c34a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f75924c1734561b91ca10f404ec367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e9cc75027443cabbe8e98e5e82dba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c337deaea94ad08f531818de003334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40eb29a9015f44aeadde79861a8fc5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f26bd9599d47cebb0ddd59b888e83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61eed2b86a4d429c91dcc8fc132945f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4720caba81ee425a9412c64c91a53b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b530295ece3e4b098bf86cd7a3501cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573957bb86ee48e29e0b3c6c2d66ea1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ce261627b54073b1decb840aec7075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b511141883d41eab487585c85591e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2e5288994e4ba9a02f18dfdc8ac136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b700dc96d8ad4c54a50fa0f2ba80c7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7102c4740b4f455799cd560633e5e15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b191cadb8dab482abcf7e7f0eca4f3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a519471096847ba8a8ba41f97ab73de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ab613be09b44a9b8dfd583a1dad961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebad80df8b3a4ea9a1e5be8e379e8e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852981331cba48339309c9192d844a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7b37e50c664d0c841786733e6c837a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda5462988d7472aa4d5b489e4c4077a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3dfb87fc5554c3d945ad5b86fde0959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b0d442a7d54a19a68070ff4cf62cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e27e204eb146c49b51d72e12a78847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973e0421f8454700b8ce8c9aa96b1598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137346496e5f4c4982858b5e698ad6e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697cc4e4126f401f93e4434943a62f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9032d4333d0d4577b6205ecfa19c33aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a609819a8d1744e7aa031fb3d5baeb8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6307313de50244eca9bcc061178aab40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad705dfb3a31499c957a939a3ea249db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab7e0ffc6504c1db65f8623cb053276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de76a86efcc0453a9eb75a7ec7a3e435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f670630192ad4ad8a898154a354a9a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88d5aff41524e90be43a2130d4a23b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972e146f262a4950908e2799853c11d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53236d53a954477a6f7e91570024bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b1a15276b04bcbb0ae0f212a0c532b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f82eb7f503471b82f460b780f1c848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb840a53cd841939f50e9b079ab9465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1328ed992cdb40b8b7a9c4f56dc1df28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c340ba35e44f92beb3c0809986aacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'con_loss': 15.092844009399414, 'cov_loss': 2.5963964462280273, 'std_loss': 0.9734358191490173, 'loss': 11.870896339416504, 'seq_len': 50.16666793823242, 'recall_top_k': 0.8799718022346497}\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for i in range(1):\n",
    "    logger = TensorBoardLogger('src/ptls-experiments/scenario_rosbank/lightning_logs',\n",
    "                               name=f'CoLES VICReg l2Norm, hidden=1024, step={i}')\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        logger=logger,\n",
    "        num_sanity_val_steps=0,\n",
    "        gpus=1,\n",
    "        auto_select_gpus=False,\n",
    "        max_epochs=60,\n",
    "        enable_checkpointing=False,\n",
    "        deterministic=True\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, data_module)\n",
    "    print(trainer.logged_metrics)\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d31a289",
   "metadata": {},
   "source": [
    "# <font size=\"6\">Inference</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e63faf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/jovyan/.local/share/virtualenvs/ptls-experiments-Xgdpvmv-/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 96 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310ac6864b3e47c4ad3df56fc4bc3c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    iterable_inference_dataset = ParquetDataset(\n",
    "        data_files=ParquetFiles(['src/ptls-experiments/scenario_rosbank/data/train_trx.parquet',\n",
    "                                 'src/ptls-experiments/scenario_rosbank/data/test_trx.parquet'],                             \n",
    "\n",
    "                                ).data_files,\n",
    "        i_filters=[FeatureFilter(['target_flag', 'cl_id'])],\n",
    "    )\n",
    "    next(iter(iterable_inference_dataset))\n",
    "\n",
    "    inference_dl = torch.utils.data.DataLoader(\n",
    "        dataset=iterable_inference_dataset,\n",
    "        collate_fn=collate_feature_dict,\n",
    "        shuffle=False,\n",
    "        batch_size=128,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    next(iter(inference_dl)).payload\n",
    "\n",
    "    mod = InferenceModule(models[i], pandas_output=True, model_out_name='emb')\n",
    "\n",
    "    pred = pl.Trainer(gpus=1).predict(mod, inference_dl)\n",
    "\n",
    "    embeddings_train_test = pd.concat(pred, axis=0)\n",
    "    embeddings_train_test = embeddings_train_test.drop(columns='target_flag')\n",
    "\n",
    "    embeddings_train_test['cl_id'] = embeddings_train_test['cl_id'].astype('int64')\n",
    "    embeddings_train_test.to_csv(f'src/ptls-experiments/scenario_rosbank/data/norm_embeddings{i}.csv',\n",
    "                                 index=False)\n",
    "    \n",
    "    print(f'iter: {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "291e95c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cl_id</th>\n",
       "      <th>emb_0000</th>\n",
       "      <th>emb_0001</th>\n",
       "      <th>emb_0002</th>\n",
       "      <th>emb_0003</th>\n",
       "      <th>emb_0004</th>\n",
       "      <th>emb_0005</th>\n",
       "      <th>emb_0006</th>\n",
       "      <th>emb_0007</th>\n",
       "      <th>emb_0008</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_1014</th>\n",
       "      <th>emb_1015</th>\n",
       "      <th>emb_1016</th>\n",
       "      <th>emb_1017</th>\n",
       "      <th>emb_1018</th>\n",
       "      <th>emb_1019</th>\n",
       "      <th>emb_1020</th>\n",
       "      <th>emb_1021</th>\n",
       "      <th>emb_1022</th>\n",
       "      <th>emb_1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10003</td>\n",
       "      <td>-0.001731</td>\n",
       "      <td>-1.431841e-07</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.226500</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.185809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.015794</td>\n",
       "      <td>-0.015411</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>-0.000612</td>\n",
       "      <td>-0.000997</td>\n",
       "      <td>0.001858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10010</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>6.418203e-05</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>-0.000329</td>\n",
       "      <td>-0.849132</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.253986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>-0.003765</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.013684</td>\n",
       "      <td>-0.003174</td>\n",
       "      <td>-0.000692</td>\n",
       "      <td>-0.007369</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>0.178840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10011</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>2.117831e-05</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.151976</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.221929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>-0.000260</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>-0.049346</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>0.100845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10059</td>\n",
       "      <td>0.005948</td>\n",
       "      <td>2.706527e-04</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>-0.000533</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.012461</td>\n",
       "      <td>0.014339</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>0.082362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>-0.001820</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>0.006443</td>\n",
       "      <td>-0.047055</td>\n",
       "      <td>-0.003576</td>\n",
       "      <td>0.007214</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.134276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10071</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>3.852190e-05</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>-0.359909</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.122689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.009871</td>\n",
       "      <td>-0.040940</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>-0.000597</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>0.522061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5712</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>6.773246e-05</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>0.252845</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.077719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.012474</td>\n",
       "      <td>-0.006680</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>0.012806</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.064928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>7975</td>\n",
       "      <td>0.003234</td>\n",
       "      <td>1.852722e-04</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>-0.043849</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>0.088815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.005572</td>\n",
       "      <td>-0.070660</td>\n",
       "      <td>-0.000940</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>0.617823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>8507</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>4.133244e-06</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>0.121561</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.175056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009895</td>\n",
       "      <td>-0.003344</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.010507</td>\n",
       "      <td>-0.072358</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>-0.000405</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>0.164011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>8928</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>1.383075e-05</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.084627</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.130049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>-0.041317</td>\n",
       "      <td>-0.000251</td>\n",
       "      <td>-0.001775</td>\n",
       "      <td>-0.000395</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>-0.020858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>9015</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>5.176523e-05</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.474535</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.217894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021823</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>-0.000364</td>\n",
       "      <td>-0.041176</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>-0.003796</td>\n",
       "      <td>-0.000555</td>\n",
       "      <td>-0.000366</td>\n",
       "      <td>0.397138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10217 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cl_id  emb_0000      emb_0001  emb_0002  emb_0003  emb_0004  emb_0005  \\\n",
       "0    10003 -0.001731 -1.431841e-07  0.000211  0.000141 -0.000226 -0.226500   \n",
       "1    10010  0.002428  6.418203e-05  0.000138  0.002095 -0.000329 -0.849132   \n",
       "2    10011  0.000059  2.117831e-05  0.000071  0.001216 -0.000091 -0.151976   \n",
       "3    10059  0.005948  2.706527e-04  0.000318 -0.000533  0.000541  0.012461   \n",
       "4    10071  0.001036  3.852190e-05 -0.000116  0.000828 -0.000190 -0.359909   \n",
       "..     ...       ...           ...       ...       ...       ...       ...   \n",
       "100   5712  0.001882  6.773246e-05 -0.000147  0.000326 -0.000180  0.252845   \n",
       "101   7975  0.003234  1.852722e-04  0.001260  0.001907 -0.000263 -0.043849   \n",
       "102   8507 -0.000006  4.133244e-06  0.000033 -0.000081 -0.000060  0.121561   \n",
       "103   8928  0.000307  1.383075e-05 -0.000068  0.000329 -0.000062 -0.084627   \n",
       "104   9015  0.001491  5.176523e-05  0.000084 -0.000053 -0.000068 -0.474535   \n",
       "\n",
       "     emb_0006  emb_0007  emb_0008  ...  emb_1014  emb_1015  emb_1016  \\\n",
       "0    0.000022  0.000157  0.185809  ...  0.000593  0.001785  0.001677   \n",
       "1    0.000084 -0.000014  0.253986  ...  0.003688 -0.003765  0.000018   \n",
       "2    0.000113  0.000028  0.221929  ...  0.004092 -0.000260  0.000517   \n",
       "3    0.014339 -0.000130  0.082362  ...  0.004031 -0.001820  0.003598   \n",
       "4    0.000026  0.000160  0.122689  ...  0.010642  0.001145  0.000165   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "100  0.000034 -0.000014  0.077719  ...  0.002844  0.000137  0.000384   \n",
       "101  0.000233 -0.000119  0.088815  ...  0.008077  0.000226  0.000811   \n",
       "102  0.000076 -0.000003  0.175056  ...  0.009895 -0.003344  0.000480   \n",
       "103  0.000021  0.000069  0.130049  ...  0.011867  0.005993  0.000682   \n",
       "104  0.000070  0.000116  0.217894  ...  0.021823  0.000828  0.002334   \n",
       "\n",
       "     emb_1017  emb_1018  emb_1019  emb_1020  emb_1021  emb_1022  emb_1023  \n",
       "0    0.015794 -0.015411  0.001391  0.008914 -0.000612 -0.000997  0.001858  \n",
       "1    0.013684 -0.003174 -0.000692 -0.007369 -0.000346 -0.000337  0.178840  \n",
       "2    0.009177 -0.049346  0.000150  0.001325 -0.000213 -0.000085  0.100845  \n",
       "3    0.006443 -0.047055 -0.003576  0.007214 -0.000818  0.000883  0.134276  \n",
       "4    0.009871 -0.040940 -0.000459  0.000879 -0.000597 -0.000314  0.522061  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "100  0.012474 -0.006680 -0.000201  0.012806  0.000126 -0.000153 -0.064928  \n",
       "101  0.005572 -0.070660 -0.000940  0.002663  0.000113 -0.000045  0.617823  \n",
       "102  0.010507 -0.072358 -0.000196 -0.000405 -0.000138 -0.000061  0.164011  \n",
       "103  0.005578 -0.041317 -0.000251 -0.001775 -0.000395 -0.000176 -0.020858  \n",
       "104 -0.000364 -0.041176 -0.000232 -0.003796 -0.000555 -0.000366  0.397138  \n",
       "\n",
       "[10217 rows x 1025 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8e516fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs = pd.read_csv('src/ptls-experiments/scenario_rosbank/data/agg_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38638d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /home/user/conda/lib/python3.7/site-packages (from seaborn) (1.21.5)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /home/user/conda/lib/python3.7/site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: pandas>=0.25 in /home/user/conda/lib/python3.7/site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: typing_extensions in /home/user/conda/lib/python3.7/site-packages (from seaborn) (4.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/conda/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/user/conda/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/user/conda/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/user/conda/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/user/conda/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.0.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/user/conda/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.28.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/user/conda/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/user/conda/lib/python3.7/site-packages (from pandas>=0.25->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/user/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20205eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cl_id</th>\n",
       "      <th>emb_0000</th>\n",
       "      <th>emb_0001</th>\n",
       "      <th>emb_0002</th>\n",
       "      <th>emb_0003</th>\n",
       "      <th>emb_0004</th>\n",
       "      <th>emb_0005</th>\n",
       "      <th>emb_0006</th>\n",
       "      <th>emb_0007</th>\n",
       "      <th>emb_0008</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_0352</th>\n",
       "      <th>emb_0353</th>\n",
       "      <th>emb_0354</th>\n",
       "      <th>emb_0355</th>\n",
       "      <th>emb_0356</th>\n",
       "      <th>emb_0357</th>\n",
       "      <th>emb_0358</th>\n",
       "      <th>emb_0359</th>\n",
       "      <th>emb_0360</th>\n",
       "      <th>emb_0361</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10003</td>\n",
       "      <td>67.0</td>\n",
       "      <td>351750.900</td>\n",
       "      <td>5250.01370</td>\n",
       "      <td>19958.3850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10010</td>\n",
       "      <td>109.0</td>\n",
       "      <td>53243.530</td>\n",
       "      <td>488.47278</td>\n",
       "      <td>1487.9280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10011</td>\n",
       "      <td>133.0</td>\n",
       "      <td>398903.500</td>\n",
       "      <td>2999.27440</td>\n",
       "      <td>8413.3030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28595.576</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19534.5300</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10059</td>\n",
       "      <td>12.0</td>\n",
       "      <td>51841.008</td>\n",
       "      <td>4320.08400</td>\n",
       "      <td>5625.0950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10071</td>\n",
       "      <td>113.0</td>\n",
       "      <td>441330.940</td>\n",
       "      <td>3905.58350</td>\n",
       "      <td>7387.3780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.1320</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10212</th>\n",
       "      <td>5712</td>\n",
       "      <td>120.0</td>\n",
       "      <td>975464.400</td>\n",
       "      <td>8128.86960</td>\n",
       "      <td>18873.9860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19849.432</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>14912.876</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>36557.6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10213</th>\n",
       "      <td>7975</td>\n",
       "      <td>52.0</td>\n",
       "      <td>295692.560</td>\n",
       "      <td>5686.39550</td>\n",
       "      <td>10053.2310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10214</th>\n",
       "      <td>8507</td>\n",
       "      <td>206.0</td>\n",
       "      <td>1530374.400</td>\n",
       "      <td>7429.00200</td>\n",
       "      <td>20584.1500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16464.836</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10215</th>\n",
       "      <td>8928</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1472858.900</td>\n",
       "      <td>17534.03500</td>\n",
       "      <td>35396.9100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57744.953</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.9497</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10216</th>\n",
       "      <td>9015</td>\n",
       "      <td>67.0</td>\n",
       "      <td>78233.310</td>\n",
       "      <td>1167.66140</td>\n",
       "      <td>2364.2732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>742.7424</td>\n",
       "      <td>0.000</td>\n",
       "      <td>680.68567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10217 rows × 363 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cl_id  emb_0000     emb_0001     emb_0002    emb_0003  emb_0004  \\\n",
       "0      10003      67.0   351750.900   5250.01370  19958.3850       0.0   \n",
       "1      10010     109.0    53243.530    488.47278   1487.9280       0.0   \n",
       "2      10011     133.0   398903.500   2999.27440   8413.3030       0.0   \n",
       "3      10059      12.0    51841.008   4320.08400   5625.0950       0.0   \n",
       "4      10071     113.0   441330.940   3905.58350   7387.3780       0.0   \n",
       "...      ...       ...          ...          ...         ...       ...   \n",
       "10212   5712     120.0   975464.400   8128.86960  18873.9860       0.0   \n",
       "10213   7975      52.0   295692.560   5686.39550  10053.2310       0.0   \n",
       "10214   8507     206.0  1530374.400   7429.00200  20584.1500       0.0   \n",
       "10215   8928      84.0  1472858.900  17534.03500  35396.9100       0.0   \n",
       "10216   9015      67.0    78233.310   1167.66140   2364.2732       0.0   \n",
       "\n",
       "       emb_0005  emb_0006  emb_0007  emb_0008  ...   emb_0352  emb_0353  \\\n",
       "0           0.0      33.0       0.0       1.0  ...      0.000    0.0000   \n",
       "1           0.0      65.0       0.0       2.0  ...      0.000    0.0000   \n",
       "2           0.0      29.0       5.0       2.0  ...  28595.576    0.0000   \n",
       "3           0.0       1.0       0.0       1.0  ...      0.000    0.0000   \n",
       "4           0.0      17.0      20.0       4.0  ...      0.000    0.0000   \n",
       "...         ...       ...       ...       ...  ...        ...       ...   \n",
       "10212       0.0      26.0       6.0       5.0  ...  19849.432    0.0000   \n",
       "10213       0.0       3.0       8.0       6.0  ...      0.000    0.0000   \n",
       "10214       0.0      59.0      41.0       6.0  ...  16464.836    0.0000   \n",
       "10215       0.0      12.0      18.0       4.0  ...  57744.953    0.0000   \n",
       "10216       0.0      20.0      19.0       4.0  ...      0.000  742.7424   \n",
       "\n",
       "        emb_0354   emb_0355  emb_0356    emb_0357  emb_0358  emb_0359  \\\n",
       "0          0.000    0.00000       0.0      0.0000      24.0       1.0   \n",
       "1          0.000    0.00000       0.0      0.0000      20.0       1.0   \n",
       "2          0.000    0.00000       0.0  19534.5300      25.0       1.0   \n",
       "3          0.000    0.00000       0.0      0.0000       8.0       1.0   \n",
       "4          0.000    0.00000       0.0    212.1320      24.0       1.0   \n",
       "...          ...        ...       ...         ...       ...       ...   \n",
       "10212  14912.876    0.00000   36557.6      0.0000      17.0       1.0   \n",
       "10213      0.000    0.00000       0.0      0.0000      18.0       1.0   \n",
       "10214      0.000    0.00000       0.0      0.0000      28.0       1.0   \n",
       "10215      0.000    0.00000       0.0    173.9497      20.0       1.0   \n",
       "10216      0.000  680.68567       0.0      0.0000      15.0       1.0   \n",
       "\n",
       "       emb_0360  emb_0361  \n",
       "0           1.0       1.0  \n",
       "1           1.0       1.0  \n",
       "2           1.0       3.0  \n",
       "3           1.0       2.0  \n",
       "4           1.0       3.0  \n",
       "...         ...       ...  \n",
       "10212       2.0       6.0  \n",
       "10213       1.0       5.0  \n",
       "10214       1.0       5.0  \n",
       "10215       1.0       6.0  \n",
       "10216       1.0       6.0  \n",
       "\n",
       "[10217 rows x 363 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "876bc71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_train_test['cl_id'] = embeddings_train_test['cl_id'].astype('int64')\n",
    "embeddings_train_test.to_csv('src/ptls-experiments/scenario_rosbank/data/embeddings.csv',\n",
    "                             index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptls-experiments",
   "language": "python",
   "name": "ptls-experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
