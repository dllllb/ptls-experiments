{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59549d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51570287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/10 11:38:29 WARN Utils: Your hostname, vm2 resolves to a loopback address: 127.0.1.1; using 192.168.0.6 instead (on interface ens192)\n",
      "22/08/10 11:38:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/10 11:38:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/08/10 11:38:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/08/10 11:38:31 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import sys\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql import Window\n",
    "\n",
    "SparkAppName = 'alpha'\n",
    "\n",
    "# spark_home = '/opt/cloudera/parcels/SPARK2/lib/spark2'\n",
    "# os.environ['SPARK_HOME'] = spark_home\n",
    "# os.environ['PYSPARK_DRIVER_PYTHON'] = 'python'\n",
    "# os.environ['PYSPARK_PYTHON'] = '/opt/cloudera/parcels/PYENV.GPUAI-3.6.pyenv.p0.2/bin/python'\n",
    "# os.environ['LD_LIBRARY_PATH'] = '/opt/python/virtualenv/jupyter/lib'\n",
    "# sys.path.insert(0, os.path.join (spark_home,'python'))\n",
    "# sys.path.insert(0, os.path.join (spark_home,'python/lib/py4j-0.10.7-src.zip'))\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(SparkAppName)\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config('spark.driver.memory', '64g')\\\n",
    "    .config('spark.driver.maxResultSize', '16g')\\\n",
    "    .getOrCreate()\n",
    "\n",
    "#     .master(\"yarn-client\")\\\n",
    "#     .config('spark.dynamicAllocation.enabled', 'true')\\\n",
    "#     .config('spark.dynamicAllocation.minExecutors',4)\\\n",
    "#     .config('spark.executor.memory','10g')\\\n",
    "#     .config('spark.executor.cores', 7)\\\n",
    "#     .config('spark.yarn.executor.memoryOverhead', '10g')\\\n",
    "#     .config('spark.driver.memory', '6g')\\\n",
    "#     .config('spark.driver.maxResultSize','6g')\\\n",
    "#     .config('spark.kryoserializer.buffer.max', '1g')\\\n",
    "#     .config('spark.excludeOnFailure.enabled', 'true')\\\n",
    "#     .config('spark.excludeOnFailure.timeout', '3h')\\\n",
    "#     .config('spark.excludeOnFailure.task.maxTaskAttemptsPerNode', 2)\\\n",
    "#     .config('spark.sql.broadcastTimeout', 36000)\\\n",
    "#     .config('spark.sql.shuffle.partitions', 2000)\\\n",
    "#     .config('spark.sql.autoBroadcastJoinThreshold', '-1')\\\n",
    "#     .enableHiveSupport()\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c17d8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description.xlsx       test_data\ttrain_data\r\n",
      "sample_submission.csv  test_target.csv\ttrain_target.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data_for_competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd5f0d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = spark.read.csv(\"data_for_competition/train_target.csv\", header=True)\n",
    "train_target.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff7daf53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target = spark.read.csv(\"data_for_competition/test_target.csv\", header=True)\n",
    "test_target.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd258ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|flag|\n",
      "+---+----+\n",
      "|  0|   0|\n",
      "|  1|   0|\n",
      "|  2|   0|\n",
      "|  3|   0|\n",
      "|  4|   0|\n",
      "|  5|   0|\n",
      "|  6|   0|\n",
      "|  7|   0|\n",
      "|  8|   0|\n",
      "|  9|   0|\n",
      "| 10|   0|\n",
      "| 11|   0|\n",
      "| 12|   0|\n",
      "| 13|   0|\n",
      "| 14|   0|\n",
      "| 15|   0|\n",
      "| 16|   0|\n",
      "| 17|   0|\n",
      "| 18|   0|\n",
      "| 19|   0|\n",
      "+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_target.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "304cceb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:==========================================>                (5 + 2) / 7]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "106442.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.select(F.sum('flag')).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "708b09ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5480666666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "106442/3000000*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dc807ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26162717"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = spark.read.parquet(\"data_for_competition/train_data\")\n",
    "train_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "641bc00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4724601"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = spark.read.parquet(\"data_for_competition/test_data\")\n",
    "test_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bc83370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint'),\n",
       " ('rn', 'bigint'),\n",
       " ('pre_since_opened', 'bigint'),\n",
       " ('pre_since_confirmed', 'bigint'),\n",
       " ('pre_pterm', 'bigint'),\n",
       " ('pre_fterm', 'bigint'),\n",
       " ('pre_till_pclose', 'bigint'),\n",
       " ('pre_till_fclose', 'bigint'),\n",
       " ('pre_loans_credit_limit', 'bigint'),\n",
       " ('pre_loans_next_pay_summ', 'bigint'),\n",
       " ('pre_loans_outstanding', 'bigint'),\n",
       " ('pre_loans_total_overdue', 'bigint'),\n",
       " ('pre_loans_max_overdue_sum', 'bigint'),\n",
       " ('pre_loans_credit_cost_rate', 'bigint'),\n",
       " ('pre_loans5', 'bigint'),\n",
       " ('pre_loans530', 'bigint'),\n",
       " ('pre_loans3060', 'bigint'),\n",
       " ('pre_loans6090', 'bigint'),\n",
       " ('pre_loans90', 'bigint'),\n",
       " ('is_zero_loans5', 'bigint'),\n",
       " ('is_zero_loans530', 'bigint'),\n",
       " ('is_zero_loans3060', 'bigint'),\n",
       " ('is_zero_loans6090', 'bigint'),\n",
       " ('is_zero_loans90', 'bigint'),\n",
       " ('pre_util', 'bigint'),\n",
       " ('pre_over2limit', 'bigint'),\n",
       " ('pre_maxover2limit', 'bigint'),\n",
       " ('is_zero_util', 'bigint'),\n",
       " ('is_zero_over2limit', 'bigint'),\n",
       " ('is_zero_maxover2limit', 'bigint'),\n",
       " ('enc_paym_0', 'bigint'),\n",
       " ('enc_paym_1', 'bigint'),\n",
       " ('enc_paym_2', 'bigint'),\n",
       " ('enc_paym_3', 'bigint'),\n",
       " ('enc_paym_4', 'bigint'),\n",
       " ('enc_paym_5', 'bigint'),\n",
       " ('enc_paym_6', 'bigint'),\n",
       " ('enc_paym_7', 'bigint'),\n",
       " ('enc_paym_8', 'bigint'),\n",
       " ('enc_paym_9', 'bigint'),\n",
       " ('enc_paym_10', 'bigint'),\n",
       " ('enc_paym_11', 'bigint'),\n",
       " ('enc_paym_12', 'bigint'),\n",
       " ('enc_paym_13', 'bigint'),\n",
       " ('enc_paym_14', 'bigint'),\n",
       " ('enc_paym_15', 'bigint'),\n",
       " ('enc_paym_16', 'bigint'),\n",
       " ('enc_paym_17', 'bigint'),\n",
       " ('enc_paym_18', 'bigint'),\n",
       " ('enc_paym_19', 'bigint'),\n",
       " ('enc_paym_20', 'bigint'),\n",
       " ('enc_paym_21', 'bigint'),\n",
       " ('enc_paym_22', 'bigint'),\n",
       " ('enc_paym_23', 'bigint'),\n",
       " ('enc_paym_24', 'bigint'),\n",
       " ('enc_loans_account_holder_type', 'bigint'),\n",
       " ('enc_loans_credit_status', 'bigint'),\n",
       " ('enc_loans_credit_type', 'bigint'),\n",
       " ('enc_loans_account_cur', 'bigint'),\n",
       " ('pclose_flag', 'bigint'),\n",
       " ('fclose_flag', 'bigint')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_data.dtypes))\n",
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03e4f1c",
   "metadata": {},
   "source": [
    "### Add 1 to all except rn col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8552237",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train_data.columns:\n",
    "    if column != 'id' and column != 'rn' and column != 'enc_paym_24' and column != 'enc_paym_20' and column != 'enc_paym_11' and column != 'pre_loans90' and column != 'pre_loans_outstanding':\n",
    "        train_data = train_data.withColumn(column, F.col(column) + F.lit(1))\n",
    "        test_data = test_data.withColumn(column, F.col(column) + F.lit(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13497d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/10 11:38:43 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rn</th>\n",
       "      <th>pre_since_opened</th>\n",
       "      <th>pre_since_confirmed</th>\n",
       "      <th>pre_pterm</th>\n",
       "      <th>pre_fterm</th>\n",
       "      <th>pre_till_pclose</th>\n",
       "      <th>pre_till_fclose</th>\n",
       "      <th>pre_loans_credit_limit</th>\n",
       "      <th>pre_loans_next_pay_summ</th>\n",
       "      <th>...</th>\n",
       "      <th>enc_paym_21</th>\n",
       "      <th>enc_paym_22</th>\n",
       "      <th>enc_paym_23</th>\n",
       "      <th>enc_paym_24</th>\n",
       "      <th>enc_loans_account_holder_type</th>\n",
       "      <th>enc_loans_credit_status</th>\n",
       "      <th>enc_loans_credit_type</th>\n",
       "      <th>enc_loans_account_cur</th>\n",
       "      <th>pclose_flag</th>\n",
       "      <th>fclose_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250000</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250000</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250000</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250000</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250000</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>250014</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>250014</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>250014</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>250014</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>250015</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  rn  pre_since_opened  pre_since_confirmed  pre_pterm  pre_fterm  \\\n",
       "0   250000   1                 9                    8          8          3   \n",
       "1   250000   2                15                    9         13         11   \n",
       "2   250000   3                11                    5          9         12   \n",
       "3   250000   4                14                   13          9          7   \n",
       "4   250000   5                 7                   13          5         15   \n",
       "..     ...  ..               ...                  ...        ...        ...   \n",
       "95  250014   7                 7                    3          1          9   \n",
       "96  250014   8                12                   18          9         12   \n",
       "97  250014   9                 2                   10          5          9   \n",
       "98  250014  10                13                   11         17          9   \n",
       "99  250015   1                 8                   10          5          9   \n",
       "\n",
       "    pre_till_pclose  pre_till_fclose  pre_loans_credit_limit  \\\n",
       "0                 5               10                       6   \n",
       "1                 7                4                      13   \n",
       "2                 7               14                       6   \n",
       "3                14                6                      13   \n",
       "4                 2                8                       5   \n",
       "..              ...              ...                     ...   \n",
       "95               15               12                      12   \n",
       "96               16               15                       5   \n",
       "97                2               12                      16   \n",
       "98               13                3                      15   \n",
       "99                2               12                      11   \n",
       "\n",
       "    pre_loans_next_pay_summ  ...  enc_paym_21  enc_paym_22  enc_paym_23  \\\n",
       "0                         3  ...            4            4            4   \n",
       "1                         7  ...            4            4            4   \n",
       "2                         3  ...            4            4            4   \n",
       "3                         3  ...            4            4            4   \n",
       "4                         3  ...            4            4            4   \n",
       "..                      ...  ...          ...          ...          ...   \n",
       "95                        3  ...            1            1            1   \n",
       "96                        3  ...            4            4            4   \n",
       "97                        6  ...            4            4            4   \n",
       "98                        3  ...            4            4            4   \n",
       "99                        5  ...            4            4            4   \n",
       "\n",
       "    enc_paym_24  enc_loans_account_holder_type  enc_loans_credit_status  \\\n",
       "0             4                              2                        4   \n",
       "1             4                              2                        4   \n",
       "2             4                              2                        4   \n",
       "3             4                              2                        4   \n",
       "4             4                              2                        4   \n",
       "..          ...                            ...                      ...   \n",
       "95            1                              2                        3   \n",
       "96            4                              2                        4   \n",
       "97            4                              2                        3   \n",
       "98            4                              2                        4   \n",
       "99            4                              2                        3   \n",
       "\n",
       "    enc_loans_credit_type  enc_loans_account_cur  pclose_flag  fclose_flag  \n",
       "0                       5                      2            1            1  \n",
       "1                       5                      2            1            1  \n",
       "2                       5                      2            1            1  \n",
       "3                       5                      2            1            1  \n",
       "4                       2                      2            2            1  \n",
       "..                    ...                    ...          ...          ...  \n",
       "95                      4                      2            1            2  \n",
       "96                      4                      2            1            1  \n",
       "97                      4                      2            2            2  \n",
       "98                      2                      2            1            1  \n",
       "99                      5                      2            2            2  \n",
       "\n",
       "[100 rows x 61 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.limit(100).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a71387f",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fd324d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num clients in train:  3000000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 27:=============================================>       (171 + 25) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max num trx:  58\n",
      "Min num trx:  1\n",
      "Mean num trx:  8.720905666666667\n",
      "\n",
      "% of clients with 1 trx:  7.35\n",
      "% of clients with 2 trx:  7.62\n",
      "% of clients < 5 trx:  30.19\n",
      "% of clients < 10 trx:  62.32\n",
      "% of clients > 30 trx:  0.27\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD4CAYAAAAdIcpQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQnklEQVR4nO3df6yeZX3H8fdnoI75iyJdQyhZ2Ww0zMyKDdRoFpSsFFwGS5iBLNKYzi4REk1MtrIlY9OZ4B/TSeJImHSUxYkMdTSI1q6SmP0BclDkp6xnCKEN0EoRlpm54b7747mqD/XpuXp+9JzznPN+JXee+/7ev64rPPTT677v526qCkmSpvJLC90ASdLiZ1hIkroMC0lSl2EhSeoyLCRJXScudAPm2qmnnlpr1qxZ6GZI0li57777flhVK4+2fsmFxZo1a5iYmFjoZkjSWEny5FTrvQwlSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqWnK/4D7e1mz76s/mn7j2vQvYEkmaP4bFURgKkvRzXoaSJHU5spgjjkQkLWWOLCRJXYaFJKnLsJAkdRkWkqQub3APGb5JLUn6OUcWkqQuw0KS1OVlqOPsyEtb/gZD0jhyZCFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSlz/Km2f+I0mSxpEjC0lSl2EhSeoyLCRJXd2wSHJGkruSPJLk4SQfbvVTkuxOsrd9rmj1JLkuyWSSB5KcPXSszW37vUk2D9XfnuTBts91STLVOSRJ8+tYRhYvAR+tqrOADcCVSc4CtgF7qmotsKctA1wIrG3TVuB6GPzBD1wDnAucA1wz9If/9cAHh/bb1OpHO4ckaR51w6Kqnq6q77T5/wQeBU4HLgZ2tM12AJe0+YuBm2vgbuDkJKcBFwC7q+pQVT0P7AY2tXWvq6q7q6qAm4841qhzSJLm0bTuWSRZA7wNuAdYVVVPt1XPAKva/OnAU0O77Wu1qer7RtSZ4hxHtmtrkokkEwcPHpxOlyRJx+CYwyLJa4AvAR+pqheH17URQc1x215mqnNU1Q1Vtb6q1q9cufJ4NkOSlqVjCoskr2AQFJ+vqi+38rPtEhLt80Cr7wfOGNp9datNVV89oj7VOSRJ8+hYnoYKcCPwaFV9amjVTuDwE02bgduH6le0p6I2AC+0S0m7gI1JVrQb2xuBXW3di0k2tHNdccSxRp1DkjSPjuV1H+8E3g88mOT+Vvsz4Frg1iRbgCeB97V1dwIXAZPAj4EPAFTVoSQfB+5t232sqg61+Q8BNwEnAV9rE1OcQ5I0j7phUVX/BuQoq88fsX0BVx7lWNuB7SPqE8BbRtSfG3WOpch3RklazPwFtySpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUdSxvndUC8gWDkhYDRxaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnq8q2zY8q30UqaT44sJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXd2wSLI9yYEkDw3V/jLJ/iT3t+mioXVXJ5lM8liSC4bqm1ptMsm2ofqZSe5p9S8meWWrv6otT7b1a+as15KkaTmWkcVNwKYR9U9X1bo23QmQ5CzgMuA32z5/l+SEJCcAnwUuBM4CLm/bAnyyHeuNwPPAllbfAjzf6p9u20mSFkA3LKrqW8ChYzzexcAtVfWTqvoBMAmc06bJqnq8qv4HuAW4OEmA9wC3tf13AJcMHWtHm78NOL9tL0maZ7O5Z3FVkgfaZaoVrXY68NTQNvta7Wj1NwA/qqqXjqi/7Fht/Qtt+1+QZGuSiSQTBw8enEWXJEmjzDQsrgd+A1gHPA38zVw1aCaq6oaqWl9V61euXLmQTZGkJWlGryivqmcPzyf5e+COtrgfOGNo09WtxlHqzwEnJzmxjR6Gtz98rH1JTgRe37bXEXxduaTjbUYjiySnDS3+PnD4SamdwGXtSaYzgbXAt4F7gbXtyadXMrgJvrOqCrgLuLTtvxm4fehYm9v8pcA32/aSpHnWHVkk+QJwHnBqkn3ANcB5SdYBBTwB/DFAVT2c5FbgEeAl4Mqq+mk7zlXALuAEYHtVPdxO8afALUn+GvgucGOr3wj8Y5JJBjfYL5ttZyVJM9MNi6q6fET5xhG1w9t/AvjEiPqdwJ0j6o8zeFrqyPp/A3/Qa58k6fjzF9ySpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1DWjt85qPPg2WklzxZGFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSunzr7DLk22glTZcjC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV3dsEiyPcmBJA8N1U5JsjvJ3va5otWT5Lokk0keSHL20D6b2/Z7k2weqr89yYNtn+uSZKpz6PhZs+2rP5skadixjCxuAjYdUdsG7KmqtcCetgxwIbC2TVuB62HwBz9wDXAucA5wzdAf/tcDHxzab1PnHJKkedYNi6r6FnDoiPLFwI42vwO4ZKh+cw3cDZyc5DTgAmB3VR2qqueB3cCmtu51VXV3VRVw8xHHGnUOSdI8m+k9i1VV9XSbfwZY1eZPB54a2m5fq01V3zeiPtU5fkGSrUkmkkwcPHhwBt2RJE1l1je424ig5qAtMz5HVd1QVeurav3KlSuPZ1MkaVmaaVg82y4h0T4PtPp+4Iyh7Va32lT11SPqU51DkjTPZhoWO4HDTzRtBm4fql/RnoraALzQLiXtAjYmWdFubG8EdrV1LybZ0J6CuuKIY406hyRpnnX/WdUkXwDOA05Nso/BU03XArcm2QI8CbyvbX4ncBEwCfwY+ABAVR1K8nHg3rbdx6rq8E3zDzF44uok4GttYopzSJLmWTcsquryo6w6f8S2BVx5lONsB7aPqE8AbxlRf27UOSRJ889fcEuSugwLSVKXYSFJ6ures9DyNPx+qCeufe8CtkTSYuDIQpLUZVhIkroMC0lSl2EhSeoyLCRJXT4NpWnxKSlpeXJkIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSuvydheaEv7+QljZHFpKkLsNCktRlWEiSugwLSVKXN7h1XHnjW1oaHFlIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdfnorOaNj9FK48uRhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVLXrMIiyRNJHkxyf5KJVjslye4ke9vnilZPkuuSTCZ5IMnZQ8fZ3Lbfm2TzUP3t7fiTbd/Mpr1avNZs++rPJkmLz1yMLN5dVeuqan1b3gbsqaq1wJ62DHAhsLZNW4HrYRAuwDXAucA5wDWHA6Zt88Gh/TbNQXslSdN0PC5DXQzsaPM7gEuG6jfXwN3AyUlOAy4AdlfVoap6HtgNbGrrXldVd1dVATcPHUuSNI9mGxYFfCPJfUm2ttqqqnq6zT8DrGrzpwNPDe27r9Wmqu8bUf8FSbYmmUgycfDgwdn0R5I0wmxf9/Guqtqf5FeB3Um+P7yyqipJzfIcXVV1A3ADwPr164/7+SRpuZnVyKKq9rfPA8BXGNxzeLZdQqJ9Hmib7wfOGNp9datNVV89oi5JmmczDoskr07y2sPzwEbgIWAncPiJps3A7W1+J3BFeypqA/BCu1y1C9iYZEW7sb0R2NXWvZhkQ3sK6oqhY0mS5tFsLkOtAr7SnmY9Efinqvp6knuBW5NsAZ4E3te2vxO4CJgEfgx8AKCqDiX5OHBv2+5jVXWozX8IuAk4Cfham7SM+KZaaXGYcVhU1ePAW0fUnwPOH1Ev4MqjHGs7sH1EfQJ4y0zbKEmaG/6CW5LUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKlrtq/7kBaEv7+Q5pcjC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuH53V2PMxWun4c2QhSeoyLCRJXYaFJKnLsJAkdXmDW0uWN76luePIQpLUZVhIkroMC0lSl2EhSeryBreWHW98S9PnyEKS1GVYSJK6DAtJUpf3LKTGexnS0TmykCR1GRaSpC4vQ0kjeElKejlHFpKkLkcW0jQ44tBy5chCktTlyEKaA444tNQZFtJxZIhoqVj0YZFkE/AZ4ATgc1V17QI3SZoRg0PjbFGHRZITgM8CvwPsA+5NsrOqHlnYlklzZ6oQMWC0WCzqsADOASar6nGAJLcAFwOGhZa14RAZNhwoRwsaA0gzkapa6DYcVZJLgU1V9Udt+f3AuVV11RHbbQW2tsU3AY8dw+FPBX44h81dDJZin2Bp9ss+jY+l2K9Rffq1qlp5tB0W+8jimFTVDcAN09knyURVrT9OTVoQS7FPsDT7ZZ/Gx1Ls10z6tNh/Z7EfOGNoeXWrSZLm0WIPi3uBtUnOTPJK4DJg5wK3SZKWnUV9GaqqXkpyFbCLwaOz26vq4Tk6/LQuW42JpdgnWJr9sk/jYyn2a9p9WtQ3uCVJi8NivwwlSVoEDAtJUteyC4skm5I8lmQyybaFbs9MJdme5ECSh4ZqpyTZnWRv+1yxkG2criRnJLkrySNJHk7y4VYf9379cpJvJ/le69dftfqZSe5p38Uvtoc4xkqSE5J8N8kdbXms+5TkiSQPJrk/yUSrjfX3DyDJyUluS/L9JI8mecd0+7WswmLo9SEXAmcBlyc5a2FbNWM3AZuOqG0D9lTVWmBPWx4nLwEfraqzgA3Ale2/z7j36yfAe6rqrcA6YFOSDcAngU9X1RuB54EtC9fEGfsw8OjQ8lLo07urat3Q7xDG/fsHg/frfb2q3gy8lcF/s+n1q6qWzQS8A9g1tHw1cPVCt2sW/VkDPDS0/BhwWps/DXhsods4y/7dzuC9YEumX8CvAN8BzmXwC9oTW/1l381xmBj87mkP8B7gDiBLoE9PAKceURvr7x/weuAHtAeaZtqvZTWyAE4Hnhpa3tdqS8Wqqnq6zT8DrFrIxsxGkjXA24B7WAL9apdr7gcOALuB/wB+VFUvtU3G8bv4t8CfAP/Xlt/A+PepgG8kua+9RgjG//t3JnAQ+Id2yfBzSV7NNPu13MJi2ajBXxfG8rnoJK8BvgR8pKpeHF43rv2qqp9W1ToGfxs/B3jzwrZodpL8LnCgqu5b6LbMsXdV1dkMLlVfmeS3h1eO6ffvROBs4PqqehvwXxxxyelY+rXcwmKpvz7k2SSnAbTPAwvcnmlL8goGQfH5qvpyK499vw6rqh8BdzG4RHNyksM/jB237+I7gd9L8gRwC4NLUZ9hvPtEVe1vnweArzAI9nH//u0D9lXVPW35NgbhMa1+LbewWOqvD9kJbG7zmxlc8x8bSQLcCDxaVZ8aWjXu/VqZ5OQ2fxKD+zCPMgiNS9tmY9Wvqrq6qlZX1RoG/x99s6r+kDHuU5JXJ3nt4XlgI/AQY/79q6pngKeSvKmVzmfwzzxMr18LffNlAW72XAT8O4Nrxn++0O2ZRT++ADwN/C+DvzlsYXDNeA+wF/hX4JSFbuc0+/QuBkPhB4D723TREujXbwHfbf16CPiLVv914NvAJPDPwKsWuq0z7N95wB3j3qfW9u+16eHDfz6M+/ev9WEdMNG+g/8CrJhuv3zdhySpa7ldhpIkzYBhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktT1/3cjDT7b7/qmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|    id|number|\n",
      "+------+------+\n",
      "|250267|     5|\n",
      "|250622|    15|\n",
      "|250722|     4|\n",
      "|250780|    17|\n",
      "|250953|     4|\n",
      "|250956|     1|\n",
      "|251092|    10|\n",
      "|251310|     4|\n",
      "|251492|    19|\n",
      "|251605|     7|\n",
      "|251719|     1|\n",
      "|251952|     6|\n",
      "|252057|    14|\n",
      "|252993|    13|\n",
      "|253095|     1|\n",
      "|253232|    11|\n",
      "|253472|    14|\n",
      "|253498|     8|\n",
      "|253804|    13|\n",
      "|253815|     9|\n",
      "+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "agg = train_data.groupBy('id').agg(F.count(F.lit(1)).alias(\"number\")).cache()\n",
    "\n",
    "print()\n",
    "print('Num clients in train: ', agg.count())\n",
    "print()\n",
    "print('Max num trx: ', agg.select(F.max('number').alias('max')).collect()[0]['max'])\n",
    "print('Min num trx: ', agg.select(F.min('number').alias('min')).collect()[0]['min'])\n",
    "print('Mean num trx: ', agg.select(F.mean('number').alias('mean')).collect()[0]['mean'])\n",
    "print()\n",
    "lens = np.array(agg.select('number').collect())\n",
    "print('% of clients with 1 trx: ', round(np.sum(lens.squeeze() == 1)/len(lens) * 100, 2))\n",
    "print('% of clients with 2 trx: ', round(np.sum(lens.squeeze() == 2)/len(lens) * 100, 2))\n",
    "print('% of clients < 5 trx: ', round(np.sum(lens.squeeze() < 5)/len(lens) * 100, 2))\n",
    "print('% of clients < 10 trx: ', round(np.sum(lens.squeeze() < 10)/len(lens) * 100, 2))\n",
    "print('% of clients > 30 trx: ', round(np.sum(lens.squeeze() > 30)/len(lens) * 100, 2))\n",
    "plt.hist(lens, bins=100)\n",
    "plt.show()\n",
    "\n",
    "agg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81babe20",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7be0ba92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num clients in train:  500000\n",
      "\n",
      "Max num trx:  57\n",
      "Min num trx:  1\n",
      "Mean num trx:  9.449202\n",
      "\n",
      "% of clients with 1 trx:  6.94\n",
      "% of clients with 2 trx:  7.07\n",
      "% of clients < 5 trx:  27.84\n",
      "% of clients < 10 trx:  57.5\n",
      "% of clients > 30 trx:  0.37\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|     id|number|\n",
      "+-------+------+\n",
      "|3250053|    12|\n",
      "|3250074|     4|\n",
      "|3250218|     3|\n",
      "|3250294|    12|\n",
      "|3250308|     8|\n",
      "|3250333|    17|\n",
      "|3250394|     1|\n",
      "|3251104|     2|\n",
      "|3251171|    21|\n",
      "|3251607|    13|\n",
      "|3251786|     1|\n",
      "|3251883|    19|\n",
      "|3252246|     6|\n",
      "|3252721|     5|\n",
      "|3252799|    18|\n",
      "|3253046|     1|\n",
      "|3253172|    17|\n",
      "|3253292|     3|\n",
      "|3253341|    21|\n",
      "|3253386|    12|\n",
      "+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agg_test = test_data.groupBy('id').agg(F.count(F.lit(1)).alias(\"number\")).cache()\n",
    "\n",
    "print()\n",
    "print('Num clients in train: ', agg_test.count())\n",
    "print()\n",
    "print('Max num trx: ', agg_test.select(F.max('number').alias('max')).collect()[0]['max'])\n",
    "print('Min num trx: ', agg_test.select(F.min('number').alias('min')).collect()[0]['min'])\n",
    "print('Mean num trx: ', agg_test.select(F.mean('number').alias('mean')).collect()[0]['mean'])\n",
    "print()\n",
    "lens_test = np.array(agg_test.select('number').collect())\n",
    "print('% of clients with 1 trx: ', round(np.sum(lens_test.squeeze() == 1)/len(lens_test) * 100, 2))\n",
    "print('% of clients with 2 trx: ', round(np.sum(lens_test.squeeze() == 2)/len(lens_test) * 100, 2))\n",
    "print('% of clients < 5 trx: ', round(np.sum(lens_test.squeeze() < 5)/len(lens_test) * 100, 2))\n",
    "print('% of clients < 10 trx: ', round(np.sum(lens_test.squeeze() < 10)/len(lens_test) * 100, 2))\n",
    "print('% of clients > 30 trx: ', round(np.sum(lens_test.squeeze() > 30)/len(lens_test) * 100, 2))\n",
    "plt.hist(lens_test, bins=100)\n",
    "plt.show()\n",
    "\n",
    "agg_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffe355fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.3515"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(lens.squeeze() < 2)/len(lens)* 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368ecd22",
   "metadata": {},
   "source": [
    "### Number of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b575e161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                             3000000    0          2999999    |     500000     3000000    3499999\n",
      "rn                             58         1          58         |     57         1          57\n",
      "pre_since_opened               20         1          20         |     20         1          20\n",
      "pre_since_confirmed            18         1          18         |     17         1          18\n",
      "pre_pterm                      18         1          18         |     18         1          18\n",
      "pre_fterm                      17         1          17         |     17         1          17\n",
      "pre_till_pclose                17         1          17         |     17         1          17\n",
      "pre_till_fclose                16         1          16         |     16         1          16\n",
      "pre_loans_credit_limit         20         1          20         |     20         1          20\n",
      "pre_loans_next_pay_summ        7          1          7          |     8          1          8\n",
      "pre_loans_outstanding          5          1          5          |     5          1          5\n",
      "pre_loans_total_overdue        2          1          2          |     1          1          1\n",
      "pre_loans_max_overdue_sum      4          1          4          |     3          2          4\n",
      "pre_loans_credit_cost_rate     14         1          14         |     14         1          14\n",
      "pre_loans5                     13         1          17         |     17         1          18\n",
      "pre_loans530                   20         1          20         |     20         1          20\n",
      "pre_loans3060                  10         1          10         |     9          1          10\n",
      "pre_loans6090                  5          1          5          |     6          1          6\n",
      "pre_loans90                    7          2          19         |     11         1          19\n",
      "is_zero_loans5                 2          1          2          |     2          1          2\n",
      "is_zero_loans530               2          1          2          |     2          1          2\n",
      "is_zero_loans3060              2          1          2          |     2          1          2\n",
      "is_zero_loans6090              2          1          2          |     2          1          2\n",
      "is_zero_loans90                2          1          2          |     2          1          2\n",
      "pre_util                       20         1          20         |     20         1          20\n",
      "pre_over2limit                 20         1          20         |     20         1          20\n",
      "pre_maxover2limit              20         1          20         |     20         1          20\n",
      "is_zero_util                   2          1          2          |     2          1          2\n",
      "is_zero_over2limit             2          1          2          |     2          1          2\n",
      "is_zero_maxover2limit          2          1          2          |     2          1          2\n",
      "enc_paym_0                     4          1          4          |     4          1          4\n",
      "enc_paym_1                     4          1          4          |     4          1          4\n",
      "enc_paym_2                     4          1          4          |     4          1          4\n",
      "enc_paym_3                     4          1          4          |     4          1          4\n",
      "enc_paym_4                     4          1          4          |     4          1          4\n",
      "enc_paym_5                     4          1          4          |     4          1          4\n",
      "enc_paym_6                     4          1          4          |     4          1          4\n",
      "enc_paym_7                     4          1          4          |     4          1          4\n",
      "enc_paym_8                     4          1          4          |     4          1          4\n",
      "enc_paym_9                     4          1          4          |     4          1          4\n",
      "enc_paym_10                    4          1          4          |     4          1          4\n",
      "enc_paym_11                    4          1          4          |     4          1          4\n",
      "enc_paym_12                    4          1          4          |     4          1          4\n",
      "enc_paym_13                    4          1          4          |     4          1          4\n",
      "enc_paym_14                    4          1          4          |     4          1          4\n",
      "enc_paym_15                    4          1          4          |     4          1          4\n",
      "enc_paym_16                    4          1          4          |     4          1          4\n",
      "enc_paym_17                    4          1          4          |     4          1          4\n",
      "enc_paym_18                    4          1          4          |     4          1          4\n",
      "enc_paym_19                    4          1          4          |     4          1          4\n",
      "enc_paym_20                    4          1          4          |     4          1          4\n",
      "enc_paym_21                    4          1          4          |     4          1          4\n",
      "enc_paym_22                    4          1          4          |     4          1          4\n",
      "enc_paym_23                    4          1          4          |     4          1          4\n",
      "enc_paym_24                    4          1          4          |     4          1          4\n",
      "enc_loans_account_holder_type  7          1          7          |     7          1          7\n",
      "enc_loans_credit_status        7          1          7          |     7          1          7\n",
      "enc_loans_credit_type          8          1          8          |     8          1          8\n",
      "enc_loans_account_cur          4          1          4          |     4          1          4\n",
      "pclose_flag                    2          1          2          |     2          1          2\n",
      "fclose_flag                    2          1          2          |     2          1          2\n"
     ]
    }
   ],
   "source": [
    "for col in train_data.columns:\n",
    "    distinct_in_col_train = train_data.select(F.col(col)).distinct()\n",
    "    distinct_in_col_test = test_data.select(F.col(col)).distinct()\n",
    "    print('{0: <30} {1: <10} {2: <10} {3: <10} |     {4: <10} {5: <10} {6}'.format(col, train_data.select(F.col(col)).distinct().count(),\n",
    "                                                                                  distinct_in_col_train.select(F.min(F.col(col))).toPandas().to_numpy().squeeze().tolist(),\n",
    "                                                                                  distinct_in_col_train.select(F.max(F.col(col))).toPandas().to_numpy().squeeze().tolist(),\n",
    "                                                                                  test_data.select(F.col(col)).distinct().count(),\n",
    "                                                                                  distinct_in_col_test.select(F.min(F.col(col))).toPandas().to_numpy().squeeze().tolist(),\n",
    "                                                                                  distinct_in_col_test.select(F.max(F.col(col))).toPandas().to_numpy().squeeze().tolist()\n",
    "                                                                            )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132047bf",
   "metadata": {},
   "source": [
    "### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b19a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in train_data.columns:\n",
    "#     print(np.sum(train_data.select([F.count(F.when(F.isnan(c) | F.isnull(c), c))]).toPandas().to_numpy().squeeze()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be3c76",
   "metadata": {},
   "source": [
    "### Check for zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3260ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in train_data.columns:\n",
    "#     print(np.sum(train_data.filter(train_data[c] == 0).limit(100).toPandas().to_numpy().squeeze()), c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc495e",
   "metadata": {},
   "source": [
    "### Collect lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2721b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_train_df = train_data.groupBy('id').agg(*[F.collect_list(col).alias(col) for col in train_data.columns if col != 'id']).join(train_target, ['id']).withColumn('rn', F.reverse('rn'))\n",
    "# full_train_df = full_train_df.withColumn('flag', full_train_df['flag'].cast('int')).cache()\n",
    "# valid_df = full_train_df.sample(0.01).cache()\n",
    "# train_df = full_train_df.join(valid_df, full_train_df.id == valid_df.id, how='left_anti').cache()\n",
    "# test_df = test_data.groupBy('id').agg(*[F.collect_list(col).alias(col) for col in test_data.columns if col != 'id']).withColumn('rn', F.reverse('rn')).cache()\n",
    "\n",
    "# print('Full train size:', full_train_df.count())\n",
    "# print('Valid size:', valid_df.count())\n",
    "# print('Train size:', train_df.count())\n",
    "# print('Test size:', test_df.count())\n",
    "\n",
    "# full_train_df.write.parquet(\"./full_train.parquet\")\n",
    "# train_df.write.parquet(\"./train.parquet\")\n",
    "# valid_df.write.parquet(\"./valid.parquet\")\n",
    "# test_df.write.parquet(\"./test.parquet\")\n",
    "\n",
    "full_train_df = spark.read.parquet(\"./full_train.parquet\")\n",
    "train_df = spark.read.parquet(\"./train.parquet\")\n",
    "valid_df = spark.read.parquet(\"./valid.parquet\")\n",
    "test_df = spark.read.parquet(\"./test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c22b6724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_train_df_gt2 = full_train_df.filter(F.size(full_train_df.rn) > 2)\n",
    "# full_train_df_gt2.write.parquet(\"./full_train_gt2.parquet\")\n",
    "\n",
    "# valid_df_gt2 = full_train_df_gt2.sample(0.01).cache()\n",
    "# train_df_gt2 = full_train_df_gt2.join(valid_df_gt2, full_train_df_gt2.id == valid_df_gt2.id, how='left_anti').cache()\n",
    "\n",
    "# train_df_gt2.write.parquet(\"./train_gt2.parquet\")\n",
    "# valid_df_gt2.write.parquet(\"./valid_gt2.parquet\")\n",
    "\n",
    "full_train_df_gt2 = spark.read.parquet(\"./full_train_gt2.parquet\")\n",
    "train_df_gt2 = spark.read.parquet(\"./train_gt2.parquet\")\n",
    "valid_df_gt2 = spark.read.parquet(\"./valid_gt2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49f68057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.753479125248509"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df_gt2.select(F.sum('flag')).collect()[0][0] / 30180 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9826f93c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rn</th>\n",
       "      <th>pre_since_opened</th>\n",
       "      <th>pre_since_confirmed</th>\n",
       "      <th>pre_pterm</th>\n",
       "      <th>pre_fterm</th>\n",
       "      <th>pre_till_pclose</th>\n",
       "      <th>pre_till_fclose</th>\n",
       "      <th>pre_loans_credit_limit</th>\n",
       "      <th>pre_loans_next_pay_summ</th>\n",
       "      <th>...</th>\n",
       "      <th>enc_paym_22</th>\n",
       "      <th>enc_paym_23</th>\n",
       "      <th>enc_paym_24</th>\n",
       "      <th>enc_loans_account_holder_type</th>\n",
       "      <th>enc_loans_credit_status</th>\n",
       "      <th>enc_loans_credit_type</th>\n",
       "      <th>enc_loans_account_cur</th>\n",
       "      <th>pclose_flag</th>\n",
       "      <th>fclose_flag</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>[7, 6, 5, 4, 3, 2, 1]</td>\n",
       "      <td>[9, 14, 7, 7, 19, 2, 20]</td>\n",
       "      <td>[9, 10, 9, 6, 10, 10, 10]</td>\n",
       "      <td>[10, 8, 15, 5, 2, 15, 11]</td>\n",
       "      <td>[9, 7, 8, 9, 17, 8, 14]</td>\n",
       "      <td>[5, 14, 2, 2, 12, 11, 11]</td>\n",
       "      <td>[12, 6, 12, 12, 1, 5, 5]</td>\n",
       "      <td>[6, 20, 8, 11, 12, 12, 11]</td>\n",
       "      <td>[3, 5, 3, 7, 7, 5, 7]</td>\n",
       "      <td>...</td>\n",
       "      <td>[4, 4, 4, 1, 1, 4, 4]</td>\n",
       "      <td>[4, 4, 4, 1, 1, 4, 4]</td>\n",
       "      <td>[4, 4, 4, 1, 4, 4, 4]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[6, 4, 3, 3, 4, 3, 3]</td>\n",
       "      <td>[5, 5, 5, 4, 5, 5, 5]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[1, 1, 1, 2, 1, 1, 1]</td>\n",
       "      <td>[2, 1, 1, 2, 1, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>444</td>\n",
       "      <td>[5, 4, 3, 2, 1]</td>\n",
       "      <td>[14, 7, 7, 19, 8]</td>\n",
       "      <td>[15, 15, 10, 10, 17]</td>\n",
       "      <td>[14, 4, 5, 16, 8]</td>\n",
       "      <td>[3, 6, 9, 10, 7]</td>\n",
       "      <td>[14, 4, 2, 6, 8]</td>\n",
       "      <td>[6, 6, 12, 8, 3]</td>\n",
       "      <td>[7, 14, 9, 2, 7]</td>\n",
       "      <td>[3, 3, 4, 5, 3]</td>\n",
       "      <td>...</td>\n",
       "      <td>[4, 4, 1, 4, 4]</td>\n",
       "      <td>[4, 4, 1, 4, 4]</td>\n",
       "      <td>[4, 4, 4, 4, 4]</td>\n",
       "      <td>[2, 2, 2, 2, 2]</td>\n",
       "      <td>[4, 4, 3, 4, 4]</td>\n",
       "      <td>[5, 5, 4, 5, 5]</td>\n",
       "      <td>[2, 2, 2, 2, 2]</td>\n",
       "      <td>[1, 1, 2, 1, 1]</td>\n",
       "      <td>[1, 1, 2, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>510</td>\n",
       "      <td>[13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]</td>\n",
       "      <td>[9, 16, 11, 11, 1, 14, 14, 7, 7, 5, 6, 4, 10]</td>\n",
       "      <td>[6, 4, 5, 4, 13, 9, 4, 4, 9, 7, 4, 7, 11]</td>\n",
       "      <td>[5, 10, 14, 14, 7, 18, 1, 10, 2, 5, 13, 8, 15]</td>\n",
       "      <td>[9, 1, 3, 3, 9, 15, 14, 13, 17, 13, 11, 12, 9]</td>\n",
       "      <td>[2, 10, 7, 7, 15, 6, 13, 4, 12, 2, 16, 12, 11]</td>\n",
       "      <td>[12, 2, 14, 14, 12, 11, 15, 11, 1, 8, 15, 1, 12]</td>\n",
       "      <td>[14, 4, 20, 20, 13, 9, 12, 17, 10, 17, 12, 14, 8]</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 2, 3]</td>\n",
       "      <td>...</td>\n",
       "      <td>[4, 4, 4, 4, 1, 1, 4, 4, 4, 4, 1, 4, 4]</td>\n",
       "      <td>[4, 4, 4, 4, 1, 1, 4, 4, 4, 4, 1, 4, 4]</td>\n",
       "      <td>[4, 4, 4, 4, 1, 1, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3]</td>\n",
       "      <td>[5, 2, 5, 2, 4, 5, 4, 2, 5, 4, 5, 5, 4]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1]</td>\n",
       "      <td>[2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>617</td>\n",
       "      <td>[20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9...</td>\n",
       "      <td>[9, 9, 9, 9, 9, 15, 15, 11, 1, 1, 14, 14, 14, ...</td>\n",
       "      <td>[18, 5, 5, 4, 12, 9, 10, 5, 5, 10, 11, 10, 10,...</td>\n",
       "      <td>[4, 2, 18, 8, 5, 2, 10, 14, 14, 17, 7, 15, 5, ...</td>\n",
       "      <td>[6, 17, 14, 7, 9, 15, 1, 1, 1, 7, 9, 15, 1, 9,...</td>\n",
       "      <td>[5, 7, 10, 10, 2, 14, 7, 7, 14, 14, 1, 3, 2, 2...</td>\n",
       "      <td>[10, 14, 4, 2, 12, 4, 14, 14, 4, 4, 12, 8, 6, ...</td>\n",
       "      <td>[6, 13, 18, 6, 5, 12, 6, 11, 20, 11, 3, 15, 11...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 7, 3, 2, 5, 3, 4, 5, 3, 5, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[4, 1, 1, 4, 1, 4, 4, 4, 4, 4, 1, 1, 4, 1, 1, ...</td>\n",
       "      <td>[4, 1, 1, 4, 1, 4, 4, 4, 4, 4, 1, 2, 4, 1, 1, ...</td>\n",
       "      <td>[4, 1, 1, 4, 1, 4, 4, 4, 4, 4, 1, 4, 4, 1, 4, ...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 3, ...</td>\n",
       "      <td>[5, 5, 4, 2, 4, 5, 5, 5, 5, 5, 1, 5, 4, 5, 4, ...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, ...</td>\n",
       "      <td>[1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>676</td>\n",
       "      <td>[16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4,...</td>\n",
       "      <td>[15, 11, 1, 14, 14, 14, 7, 19, 19, 5, 5, 5, 6,...</td>\n",
       "      <td>[4, 5, 15, 6, 15, 15, 10, 13, 10, 10, 10, 18, ...</td>\n",
       "      <td>[9, 10, 13, 1, 14, 10, 14, 3, 5, 3, 5, 3, 14, ...</td>\n",
       "      <td>[7, 1, 16, 9, 3, 1, 3, 11, 15, 4, 11, 15, 1, 9...</td>\n",
       "      <td>[10, 14, 4, 13, 14, 14, 4, 17, 2, 12, 2, 12, 1...</td>\n",
       "      <td>[14, 4, 6, 12, 4, 6, 6, 8, 1, 11, 1, 1, 13, 12...</td>\n",
       "      <td>[6, 9, 9, 1, 9, 18, 4, 9, 9, 8, 15, 8, 12, 12,...</td>\n",
       "      <td>[3, 1, 5, 3, 1, 4, 2, 3, 4, 4, 6, 3, 6, 3, 1, 4]</td>\n",
       "      <td>...</td>\n",
       "      <td>[4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3]</td>\n",
       "      <td>[2, 5, 5, 4, 5, 5, 5, 5, 4, 5, 4, 5, 5, 5, 4, 5]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1]</td>\n",
       "      <td>[1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>15986</td>\n",
       "      <td>[5, 4, 3, 2, 1]</td>\n",
       "      <td>[5, 18, 4, 4, 20]</td>\n",
       "      <td>[14, 13, 18, 11, 10]</td>\n",
       "      <td>[4, 4, 8, 18, 7]</td>\n",
       "      <td>[6, 6, 9, 9, 9]</td>\n",
       "      <td>[6, 17, 12, 13, 1]</td>\n",
       "      <td>[11, 13, 12, 12, 12]</td>\n",
       "      <td>[20, 20, 2, 9, 3]</td>\n",
       "      <td>[3, 3, 3, 3, 6]</td>\n",
       "      <td>...</td>\n",
       "      <td>[4, 4, 4, 1, 4]</td>\n",
       "      <td>[4, 4, 4, 4, 4]</td>\n",
       "      <td>[4, 4, 4, 4, 4]</td>\n",
       "      <td>[2, 2, 2, 2, 2]</td>\n",
       "      <td>[4, 4, 3, 3, 3]</td>\n",
       "      <td>[5, 5, 5, 4, 1]</td>\n",
       "      <td>[2, 2, 2, 2, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[1, 1, 2, 2, 2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>16350</td>\n",
       "      <td>[6, 5, 4, 3, 2, 1]</td>\n",
       "      <td>[14, 14, 14, 5, 3, 20]</td>\n",
       "      <td>[7, 2, 7, 7, 10, 17]</td>\n",
       "      <td>[4, 12, 5, 2, 15, 2]</td>\n",
       "      <td>[6, 14, 15, 17, 9, 9]</td>\n",
       "      <td>[14, 3, 2, 3, 15, 15]</td>\n",
       "      <td>[4, 7, 11, 16, 12, 12]</td>\n",
       "      <td>[19, 15, 20, 8, 8, 10]</td>\n",
       "      <td>[7, 3, 7, 4, 5, 3]</td>\n",
       "      <td>...</td>\n",
       "      <td>[4, 1, 4, 1, 4, 4]</td>\n",
       "      <td>[4, 1, 4, 2, 4, 4]</td>\n",
       "      <td>[4, 1, 4, 4, 4, 4]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[4, 4, 4, 4, 3, 3]</td>\n",
       "      <td>[5, 4, 4, 5, 5, 4]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[1, 1, 2, 1, 1, 1]</td>\n",
       "      <td>[1, 1, 1, 1, 2, 2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>16691</td>\n",
       "      <td>[11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]</td>\n",
       "      <td>[9, 9, 9, 16, 15, 14, 14, 19, 5, 5, 13]</td>\n",
       "      <td>[5, 15, 15, 9, 15, 7, 3, 10, 13, 18, 7]</td>\n",
       "      <td>[7, 13, 11, 5, 15, 8, 1, 7, 18, 18, 13]</td>\n",
       "      <td>[2, 3, 14, 14, 14, 7, 9, 2, 15, 16, 16]</td>\n",
       "      <td>[1, 10, 4, 2, 6, 14, 13, 1, 16, 3, 9]</td>\n",
       "      <td>[5, 10, 6, 4, 6, 4, 12, 5, 7, 13, 9]</td>\n",
       "      <td>[3, 11, 17, 15, 16, 13, 15, 3, 9, 16, 16]</td>\n",
       "      <td>[6, 3, 3, 3, 3, 4, 3, 6, 3, 3, 6]</td>\n",
       "      <td>...</td>\n",
       "      <td>[4, 4, 1, 4, 1, 4, 1, 1, 4, 4, 4]</td>\n",
       "      <td>[4, 4, 1, 4, 1, 4, 1, 1, 4, 4, 4]</td>\n",
       "      <td>[4, 4, 1, 4, 1, 4, 1, 1, 4, 4, 4]</td>\n",
       "      <td>[4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[3, 4, 4, 4, 4, 4, 3, 3, 4, 4, 3]</td>\n",
       "      <td>[1, 5, 5, 2, 5, 5, 4, 1, 4, 5, 5]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>16712</td>\n",
       "      <td>[13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]</td>\n",
       "      <td>[15, 15, 1, 14, 7, 7, 5, 6, 18, 12, 3, 10, 20]</td>\n",
       "      <td>[10, 10, 10, 10, 15, 10, 10, 12, 18, 10, 3, 17...</td>\n",
       "      <td>[16, 5, 17, 8, 16, 17, 2, 9, 17, 2, 15, 14, 10]</td>\n",
       "      <td>[13, 14, 10, 7, 13, 10, 11, 12, 10, 17, 9, 9, 9]</td>\n",
       "      <td>[7, 2, 14, 14, 4, 4, 3, 17, 12, 9, 15, 2, 13]</td>\n",
       "      <td>[14, 11, 4, 6, 6, 11, 1, 8, 1, 9, 12, 12, 12]</td>\n",
       "      <td>[7, 13, 14, 19, 20, 20, 18, 6, 6, 17, 8, 7, 7]</td>\n",
       "      <td>[7, 2, 7, 7, 3, 2, 2, 3, 3, 2, 3, 3, 3]</td>\n",
       "      <td>...</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3]</td>\n",
       "      <td>[5, 4, 5, 5, 6, 5, 5, 6, 5, 5, 5, 5, 5]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>16853</td>\n",
       "      <td>[8, 7, 6, 5, 4, 3, 2, 1]</td>\n",
       "      <td>[19, 5, 5, 6, 4, 12, 12, 20]</td>\n",
       "      <td>[4, 11, 18, 18, 7, 3, 3, 3]</td>\n",
       "      <td>[9, 5, 13, 17, 5, 18, 2, 16]</td>\n",
       "      <td>[7, 9, 11, 10, 3, 9, 17, 9]</td>\n",
       "      <td>[4, 2, 12, 12, 2, 9, 9, 13]</td>\n",
       "      <td>[11, 12, 1, 1, 1, 12, 9, 12]</td>\n",
       "      <td>[11, 17, 15, 11, 17, 8, 19, 14]</td>\n",
       "      <td>[3, 3, 3, 3, 3, 5, 3, 7]</td>\n",
       "      <td>...</td>\n",
       "      <td>[4, 1, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[4, 1, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[4, 1, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[4, 3, 4, 4, 4, 3, 3, 3]</td>\n",
       "      <td>[2, 4, 4, 5, 5, 5, 4, 5]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[1, 2, 1, 1, 2, 1, 1, 1]</td>\n",
       "      <td>[1, 2, 1, 1, 1, 2, 1, 2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                                 rn  \\\n",
       "0      99                              [7, 6, 5, 4, 3, 2, 1]   \n",
       "1     444                                    [5, 4, 3, 2, 1]   \n",
       "2     510        [13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]   \n",
       "3     617  [20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9...   \n",
       "4     676  [16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4,...   \n",
       "..    ...                                                ...   \n",
       "95  15986                                    [5, 4, 3, 2, 1]   \n",
       "96  16350                                 [6, 5, 4, 3, 2, 1]   \n",
       "97  16691                [11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]   \n",
       "98  16712        [13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]   \n",
       "99  16853                           [8, 7, 6, 5, 4, 3, 2, 1]   \n",
       "\n",
       "                                     pre_since_opened  \\\n",
       "0                            [9, 14, 7, 7, 19, 2, 20]   \n",
       "1                                   [14, 7, 7, 19, 8]   \n",
       "2       [9, 16, 11, 11, 1, 14, 14, 7, 7, 5, 6, 4, 10]   \n",
       "3   [9, 9, 9, 9, 9, 15, 15, 11, 1, 1, 14, 14, 14, ...   \n",
       "4   [15, 11, 1, 14, 14, 14, 7, 19, 19, 5, 5, 5, 6,...   \n",
       "..                                                ...   \n",
       "95                                  [5, 18, 4, 4, 20]   \n",
       "96                             [14, 14, 14, 5, 3, 20]   \n",
       "97            [9, 9, 9, 16, 15, 14, 14, 19, 5, 5, 13]   \n",
       "98     [15, 15, 1, 14, 7, 7, 5, 6, 18, 12, 3, 10, 20]   \n",
       "99                       [19, 5, 5, 6, 4, 12, 12, 20]   \n",
       "\n",
       "                                  pre_since_confirmed  \\\n",
       "0                           [9, 10, 9, 6, 10, 10, 10]   \n",
       "1                                [15, 15, 10, 10, 17]   \n",
       "2           [6, 4, 5, 4, 13, 9, 4, 4, 9, 7, 4, 7, 11]   \n",
       "3   [18, 5, 5, 4, 12, 9, 10, 5, 5, 10, 11, 10, 10,...   \n",
       "4   [4, 5, 15, 6, 15, 15, 10, 13, 10, 10, 10, 18, ...   \n",
       "..                                                ...   \n",
       "95                               [14, 13, 18, 11, 10]   \n",
       "96                               [7, 2, 7, 7, 10, 17]   \n",
       "97            [5, 15, 15, 9, 15, 7, 3, 10, 13, 18, 7]   \n",
       "98  [10, 10, 10, 10, 15, 10, 10, 12, 18, 10, 3, 17...   \n",
       "99                        [4, 11, 18, 18, 7, 3, 3, 3]   \n",
       "\n",
       "                                            pre_pterm  \\\n",
       "0                           [10, 8, 15, 5, 2, 15, 11]   \n",
       "1                                   [14, 4, 5, 16, 8]   \n",
       "2      [5, 10, 14, 14, 7, 18, 1, 10, 2, 5, 13, 8, 15]   \n",
       "3   [4, 2, 18, 8, 5, 2, 10, 14, 14, 17, 7, 15, 5, ...   \n",
       "4   [9, 10, 13, 1, 14, 10, 14, 3, 5, 3, 5, 3, 14, ...   \n",
       "..                                                ...   \n",
       "95                                   [4, 4, 8, 18, 7]   \n",
       "96                               [4, 12, 5, 2, 15, 2]   \n",
       "97            [7, 13, 11, 5, 15, 8, 1, 7, 18, 18, 13]   \n",
       "98    [16, 5, 17, 8, 16, 17, 2, 9, 17, 2, 15, 14, 10]   \n",
       "99                       [9, 5, 13, 17, 5, 18, 2, 16]   \n",
       "\n",
       "                                            pre_fterm  \\\n",
       "0                             [9, 7, 8, 9, 17, 8, 14]   \n",
       "1                                    [3, 6, 9, 10, 7]   \n",
       "2      [9, 1, 3, 3, 9, 15, 14, 13, 17, 13, 11, 12, 9]   \n",
       "3   [6, 17, 14, 7, 9, 15, 1, 1, 1, 7, 9, 15, 1, 9,...   \n",
       "4   [7, 1, 16, 9, 3, 1, 3, 11, 15, 4, 11, 15, 1, 9...   \n",
       "..                                                ...   \n",
       "95                                    [6, 6, 9, 9, 9]   \n",
       "96                              [6, 14, 15, 17, 9, 9]   \n",
       "97            [2, 3, 14, 14, 14, 7, 9, 2, 15, 16, 16]   \n",
       "98   [13, 14, 10, 7, 13, 10, 11, 12, 10, 17, 9, 9, 9]   \n",
       "99                        [7, 9, 11, 10, 3, 9, 17, 9]   \n",
       "\n",
       "                                      pre_till_pclose  \\\n",
       "0                           [5, 14, 2, 2, 12, 11, 11]   \n",
       "1                                    [14, 4, 2, 6, 8]   \n",
       "2      [2, 10, 7, 7, 15, 6, 13, 4, 12, 2, 16, 12, 11]   \n",
       "3   [5, 7, 10, 10, 2, 14, 7, 7, 14, 14, 1, 3, 2, 2...   \n",
       "4   [10, 14, 4, 13, 14, 14, 4, 17, 2, 12, 2, 12, 1...   \n",
       "..                                                ...   \n",
       "95                                 [6, 17, 12, 13, 1]   \n",
       "96                              [14, 3, 2, 3, 15, 15]   \n",
       "97              [1, 10, 4, 2, 6, 14, 13, 1, 16, 3, 9]   \n",
       "98      [7, 2, 14, 14, 4, 4, 3, 17, 12, 9, 15, 2, 13]   \n",
       "99                        [4, 2, 12, 12, 2, 9, 9, 13]   \n",
       "\n",
       "                                      pre_till_fclose  \\\n",
       "0                            [12, 6, 12, 12, 1, 5, 5]   \n",
       "1                                    [6, 6, 12, 8, 3]   \n",
       "2    [12, 2, 14, 14, 12, 11, 15, 11, 1, 8, 15, 1, 12]   \n",
       "3   [10, 14, 4, 2, 12, 4, 14, 14, 4, 4, 12, 8, 6, ...   \n",
       "4   [14, 4, 6, 12, 4, 6, 6, 8, 1, 11, 1, 1, 13, 12...   \n",
       "..                                                ...   \n",
       "95                               [11, 13, 12, 12, 12]   \n",
       "96                             [4, 7, 11, 16, 12, 12]   \n",
       "97               [5, 10, 6, 4, 6, 4, 12, 5, 7, 13, 9]   \n",
       "98      [14, 11, 4, 6, 6, 11, 1, 8, 1, 9, 12, 12, 12]   \n",
       "99                       [11, 12, 1, 1, 1, 12, 9, 12]   \n",
       "\n",
       "                               pre_loans_credit_limit  \\\n",
       "0                          [6, 20, 8, 11, 12, 12, 11]   \n",
       "1                                    [7, 14, 9, 2, 7]   \n",
       "2   [14, 4, 20, 20, 13, 9, 12, 17, 10, 17, 12, 14, 8]   \n",
       "3   [6, 13, 18, 6, 5, 12, 6, 11, 20, 11, 3, 15, 11...   \n",
       "4   [6, 9, 9, 1, 9, 18, 4, 9, 9, 8, 15, 8, 12, 12,...   \n",
       "..                                                ...   \n",
       "95                                  [20, 20, 2, 9, 3]   \n",
       "96                             [19, 15, 20, 8, 8, 10]   \n",
       "97          [3, 11, 17, 15, 16, 13, 15, 3, 9, 16, 16]   \n",
       "98     [7, 13, 14, 19, 20, 20, 18, 6, 6, 17, 8, 7, 7]   \n",
       "99                    [11, 17, 15, 11, 17, 8, 19, 14]   \n",
       "\n",
       "                              pre_loans_next_pay_summ  ...  \\\n",
       "0                               [3, 5, 3, 7, 7, 5, 7]  ...   \n",
       "1                                     [3, 3, 4, 5, 3]  ...   \n",
       "2             [3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 2, 3]  ...   \n",
       "3   [3, 3, 3, 3, 3, 3, 7, 3, 2, 5, 3, 4, 5, 3, 5, ...  ...   \n",
       "4    [3, 1, 5, 3, 1, 4, 2, 3, 4, 4, 6, 3, 6, 3, 1, 4]  ...   \n",
       "..                                                ...  ...   \n",
       "95                                    [3, 3, 3, 3, 6]  ...   \n",
       "96                                 [7, 3, 7, 4, 5, 3]  ...   \n",
       "97                  [6, 3, 3, 3, 3, 4, 3, 6, 3, 3, 6]  ...   \n",
       "98            [7, 2, 7, 7, 3, 2, 2, 3, 3, 2, 3, 3, 3]  ...   \n",
       "99                           [3, 3, 3, 3, 3, 5, 3, 7]  ...   \n",
       "\n",
       "                                          enc_paym_22  \\\n",
       "0                               [4, 4, 4, 1, 1, 4, 4]   \n",
       "1                                     [4, 4, 1, 4, 4]   \n",
       "2             [4, 4, 4, 4, 1, 1, 4, 4, 4, 4, 1, 4, 4]   \n",
       "3   [4, 1, 1, 4, 1, 4, 4, 4, 4, 4, 1, 1, 4, 1, 1, ...   \n",
       "4    [4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4]   \n",
       "..                                                ...   \n",
       "95                                    [4, 4, 4, 1, 4]   \n",
       "96                                 [4, 1, 4, 1, 4, 4]   \n",
       "97                  [4, 4, 1, 4, 1, 4, 1, 1, 4, 4, 4]   \n",
       "98            [4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4]   \n",
       "99                           [4, 1, 4, 4, 4, 4, 4, 4]   \n",
       "\n",
       "                                          enc_paym_23  \\\n",
       "0                               [4, 4, 4, 1, 1, 4, 4]   \n",
       "1                                     [4, 4, 1, 4, 4]   \n",
       "2             [4, 4, 4, 4, 1, 1, 4, 4, 4, 4, 1, 4, 4]   \n",
       "3   [4, 1, 1, 4, 1, 4, 4, 4, 4, 4, 1, 2, 4, 1, 1, ...   \n",
       "4    [4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4]   \n",
       "..                                                ...   \n",
       "95                                    [4, 4, 4, 4, 4]   \n",
       "96                                 [4, 1, 4, 2, 4, 4]   \n",
       "97                  [4, 4, 1, 4, 1, 4, 1, 1, 4, 4, 4]   \n",
       "98            [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]   \n",
       "99                           [4, 1, 4, 4, 4, 4, 4, 4]   \n",
       "\n",
       "                                          enc_paym_24  \\\n",
       "0                               [4, 4, 4, 1, 4, 4, 4]   \n",
       "1                                     [4, 4, 4, 4, 4]   \n",
       "2             [4, 4, 4, 4, 1, 1, 4, 4, 4, 4, 4, 4, 4]   \n",
       "3   [4, 1, 1, 4, 1, 4, 4, 4, 4, 4, 1, 4, 4, 1, 4, ...   \n",
       "4    [4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]   \n",
       "..                                                ...   \n",
       "95                                    [4, 4, 4, 4, 4]   \n",
       "96                                 [4, 1, 4, 4, 4, 4]   \n",
       "97                  [4, 4, 1, 4, 1, 4, 1, 1, 4, 4, 4]   \n",
       "98            [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]   \n",
       "99                           [4, 1, 4, 4, 4, 4, 4, 4]   \n",
       "\n",
       "                        enc_loans_account_holder_type  \\\n",
       "0                               [2, 2, 2, 2, 2, 2, 2]   \n",
       "1                                     [2, 2, 2, 2, 2]   \n",
       "2             [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]   \n",
       "3   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "4    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]   \n",
       "..                                                ...   \n",
       "95                                    [2, 2, 2, 2, 2]   \n",
       "96                                 [2, 2, 2, 2, 2, 2]   \n",
       "97                  [4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]   \n",
       "98            [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]   \n",
       "99                           [2, 2, 2, 2, 2, 2, 2, 2]   \n",
       "\n",
       "                              enc_loans_credit_status  \\\n",
       "0                               [6, 4, 3, 3, 4, 3, 3]   \n",
       "1                                     [4, 4, 3, 4, 4]   \n",
       "2             [3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3]   \n",
       "3   [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 3, ...   \n",
       "4    [4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3]   \n",
       "..                                                ...   \n",
       "95                                    [4, 4, 3, 3, 3]   \n",
       "96                                 [4, 4, 4, 4, 3, 3]   \n",
       "97                  [3, 4, 4, 4, 4, 4, 3, 3, 4, 4, 3]   \n",
       "98            [4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3]   \n",
       "99                           [4, 3, 4, 4, 4, 3, 3, 3]   \n",
       "\n",
       "                                enc_loans_credit_type  \\\n",
       "0                               [5, 5, 5, 4, 5, 5, 5]   \n",
       "1                                     [5, 5, 4, 5, 5]   \n",
       "2             [5, 2, 5, 2, 4, 5, 4, 2, 5, 4, 5, 5, 4]   \n",
       "3   [5, 5, 4, 2, 4, 5, 5, 5, 5, 5, 1, 5, 4, 5, 4, ...   \n",
       "4    [2, 5, 5, 4, 5, 5, 5, 5, 4, 5, 4, 5, 5, 5, 4, 5]   \n",
       "..                                                ...   \n",
       "95                                    [5, 5, 5, 4, 1]   \n",
       "96                                 [5, 4, 4, 5, 5, 4]   \n",
       "97                  [1, 5, 5, 2, 5, 5, 4, 1, 4, 5, 5]   \n",
       "98            [5, 4, 5, 5, 6, 5, 5, 6, 5, 5, 5, 5, 5]   \n",
       "99                           [2, 4, 4, 5, 5, 5, 4, 5]   \n",
       "\n",
       "                                enc_loans_account_cur  \\\n",
       "0                               [2, 2, 2, 2, 2, 2, 2]   \n",
       "1                                     [2, 2, 2, 2, 2]   \n",
       "2             [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]   \n",
       "3   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "4    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]   \n",
       "..                                                ...   \n",
       "95                                    [2, 2, 2, 2, 2]   \n",
       "96                                 [2, 2, 2, 2, 2, 2]   \n",
       "97                  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]   \n",
       "98            [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]   \n",
       "99                           [2, 2, 2, 2, 2, 2, 2, 2]   \n",
       "\n",
       "                                          pclose_flag  \\\n",
       "0                               [1, 1, 1, 2, 1, 1, 1]   \n",
       "1                                     [1, 1, 2, 1, 1]   \n",
       "2             [2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1]   \n",
       "3   [1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, ...   \n",
       "4    [1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1]   \n",
       "..                                                ...   \n",
       "95                                    [1, 1, 1, 1, 1]   \n",
       "96                                 [1, 1, 2, 1, 1, 1]   \n",
       "97                  [1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]   \n",
       "98            [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "99                           [1, 2, 1, 1, 2, 1, 1, 1]   \n",
       "\n",
       "                                          fclose_flag flag  \n",
       "0                               [2, 1, 1, 2, 1, 1, 1]    0  \n",
       "1                                     [1, 1, 2, 1, 1]    0  \n",
       "2             [2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2]    0  \n",
       "3   [1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, ...    0  \n",
       "4    [1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2]    0  \n",
       "..                                                ...  ...  \n",
       "95                                    [1, 1, 2, 2, 2]    0  \n",
       "96                                 [1, 1, 1, 1, 2, 2]    0  \n",
       "97                  [1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1]    0  \n",
       "98            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2]    0  \n",
       "99                           [1, 2, 1, 1, 1, 2, 1, 2]    0  \n",
       "\n",
       "[100 rows x 62 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_gt2.limit(100).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048c886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0dc390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18ca0af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b5b1276",
   "metadata": {},
   "source": [
    "### trx_encoder params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb23f150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rn': {'in': 59, 'out': 16},\n",
       " 'pre_since_opened': {'in': 21, 'out': 16},\n",
       " 'pre_since_confirmed': {'in': 19, 'out': 16},\n",
       " 'pre_pterm': {'in': 19, 'out': 16},\n",
       " 'pre_fterm': {'in': 18, 'out': 16},\n",
       " 'pre_till_pclose': {'in': 18, 'out': 16},\n",
       " 'pre_till_fclose': {'in': 17, 'out': 16},\n",
       " 'pre_loans_credit_limit': {'in': 21, 'out': 16},\n",
       " 'pre_loans_outstanding': {'in': 6, 'out': 16},\n",
       " 'pre_loans_total_overdue': {'in': 3, 'out': 16},\n",
       " 'pre_loans_max_overdue_sum': {'in': 5, 'out': 16},\n",
       " 'pre_loans_credit_cost_rate': {'in': 15, 'out': 16},\n",
       " 'is_zero_loans5': {'in': 3, 'out': 16},\n",
       " 'is_zero_loans530': {'in': 3, 'out': 16},\n",
       " 'is_zero_loans3060': {'in': 3, 'out': 16},\n",
       " 'is_zero_loans6090': {'in': 3, 'out': 16},\n",
       " 'is_zero_loans90': {'in': 3, 'out': 16},\n",
       " 'pre_util': {'in': 21, 'out': 16},\n",
       " 'pre_over2limit': {'in': 21, 'out': 16},\n",
       " 'pre_maxover2limit': {'in': 21, 'out': 16},\n",
       " 'is_zero_util': {'in': 3, 'out': 16},\n",
       " 'is_zero_over2limit': {'in': 3, 'out': 16},\n",
       " 'is_zero_maxover2limit': {'in': 3, 'out': 16},\n",
       " 'enc_paym_0': {'in': 5, 'out': 16},\n",
       " 'enc_paym_1': {'in': 5, 'out': 16},\n",
       " 'enc_paym_2': {'in': 5, 'out': 16},\n",
       " 'enc_paym_3': {'in': 5, 'out': 16},\n",
       " 'enc_paym_4': {'in': 5, 'out': 16},\n",
       " 'enc_paym_5': {'in': 5, 'out': 16},\n",
       " 'enc_paym_6': {'in': 5, 'out': 16},\n",
       " 'enc_paym_7': {'in': 5, 'out': 16},\n",
       " 'enc_paym_8': {'in': 5, 'out': 16},\n",
       " 'enc_paym_9': {'in': 5, 'out': 16},\n",
       " 'enc_paym_10': {'in': 5, 'out': 16},\n",
       " 'enc_paym_11': {'in': 5, 'out': 16},\n",
       " 'enc_paym_12': {'in': 5, 'out': 16},\n",
       " 'enc_paym_13': {'in': 5, 'out': 16},\n",
       " 'enc_paym_14': {'in': 5, 'out': 16},\n",
       " 'enc_paym_15': {'in': 5, 'out': 16},\n",
       " 'enc_paym_16': {'in': 5, 'out': 16},\n",
       " 'enc_paym_17': {'in': 5, 'out': 16},\n",
       " 'enc_paym_18': {'in': 5, 'out': 16},\n",
       " 'enc_paym_19': {'in': 5, 'out': 16},\n",
       " 'enc_paym_20': {'in': 5, 'out': 16},\n",
       " 'enc_paym_21': {'in': 5, 'out': 16},\n",
       " 'enc_paym_22': {'in': 5, 'out': 16},\n",
       " 'enc_paym_23': {'in': 5, 'out': 16},\n",
       " 'enc_paym_24': {'in': 5, 'out': 16},\n",
       " 'enc_loans_account_holder_type': {'in': 8, 'out': 16},\n",
       " 'enc_loans_credit_status': {'in': 8, 'out': 16},\n",
       " 'enc_loans_credit_type': {'in': 9, 'out': 16},\n",
       " 'enc_loans_account_cur': {'in': 5, 'out': 16},\n",
       " 'pclose_flag': {'in': 3, 'out': 16},\n",
       " 'fclose_flag': {'in': 3, 'out': 16}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_emb_dim = 16\n",
    "\n",
    "numeric_values={'pre_loans_next_pay_summ': 'identity',\n",
    "                'pre_loans5': 'identity',\n",
    "                'pre_loans530': 'identity',\n",
    "                'pre_loans3060': 'identity',\n",
    "                'pre_loans6090': 'identity',\n",
    "                'pre_loans90': 'identity'\n",
    "}\n",
    "\n",
    "embeddings={}\n",
    "for col in train_data.columns:\n",
    "    if col not in ['id'] + list(numeric_values.keys()):\n",
    "        distinct_in_col_train = train_data.select(F.col(col)).distinct()\n",
    "        max_train = distinct_in_col_train.select(F.max(F.col(col))).toPandas().to_numpy().squeeze().tolist()\n",
    "\n",
    "        distinct_in_col_test = test_data.select(F.col(col)).distinct()\n",
    "        max_test = distinct_in_col_test.select(F.max(F.col(col))).toPandas().to_numpy().squeeze().tolist()\n",
    "\n",
    "        in_dim = max(max_train, max_test) + 1\n",
    "        embeddings[col] = {'in': in_dim, 'out': feature_emb_dim}\n",
    "\n",
    "embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea14d63",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50b66b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cpc_collate_fn(batch):\n",
    "#     xs, ts = [], []\n",
    "#     for rec in batch:\n",
    "#         x, t = {k: v[:-2] for k, v in rec.items()}, {k: v[-2:] for k, v in rec.items()}\n",
    "#         xs.append(x)\n",
    "#         ts.append(t)\n",
    "#     return padded_collate_wo_target(xs), padded_collate_wo_target(ts)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    " \n",
    "from omegaconf import DictConfig\n",
    "from transformers import LongformerConfig, LongformerModel\n",
    " \n",
    "from ptls.data_load.padded_batch import PaddedBatch\n",
    "from torchmetrics import MeanMetric\n",
    "from ptls.frames.bert.losses.query_soft_max import QuerySoftmaxLoss\n",
    "from torch.nn import BCELoss\n",
    " \n",
    "\n",
    "class ContrastivePredictionHead(torch.nn.Module):\n",
    "   \n",
    "    def __init__(self, embeds_dim, drop_p=0.1):\n",
    "       \n",
    "        super().__init__()\n",
    "        self.head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embeds_dim, embeds_dim, bias=True)\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        return self.head(x)\n",
    "\n",
    "\n",
    "class MLMCPCPretrainModule(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 trx_encoder: torch.nn.Module,\n",
    "                 hidden_size: int,\n",
    "                 loss_temperature: float,\n",
    "                 total_steps: int,\n",
    "                 max_lr: float = 0.001,\n",
    "                 weight_decay: float = 0.0,\n",
    "                 pct_start: float = 0.1,\n",
    "                 norm_predict: bool = False,\n",
    "                 num_attention_heads: int = 16,\n",
    "                 intermediate_size: int = 128,\n",
    "                 num_hidden_layers: int = 2,\n",
    "                 attention_window: int = 16,\n",
    "                 hidden_dropout_prob=0,\n",
    "                 attention_probs_dropout_prob=0,\n",
    "                 max_position_embeddings: int = 4000,\n",
    "                 replace_proba: float = 0.1,\n",
    "                 neg_count: int = 1,\n",
    "                 log_logits: bool = False,\n",
    "                 weight_mlm: float = 0.5,\n",
    "                 weight_cpc: float = 0.5,\n",
    "                 encode_seq = False\n",
    "                 ):\n",
    "        \"\"\"\n",
    " \n",
    "        Parameters\n",
    "        ----------\n",
    "        trx_encoder:\n",
    "            Module for transform dict with feature sequences to sequence of transaction representations\n",
    "        hidden_size:\n",
    "            Output size of `trx_encoder`. Hidden size of internal transformer representation\n",
    "        loss_temperature:\n",
    "             temperature parameter of `QuerySoftmaxLoss`\n",
    "        total_steps:\n",
    "            total_steps expected in OneCycle lr scheduler\n",
    "        max_lr:\n",
    "            max_lr of OneCycle lr scheduler\n",
    "        weight_decay:\n",
    "            weight_decay of Adam optimizer\n",
    "        pct_start:\n",
    "            % of total_steps when lr increase\n",
    "        norm_predict:\n",
    "            use l2 norm for transformer output or not\n",
    "        num_attention_heads:\n",
    "            parameter for Longformer\n",
    "        intermediate_size:\n",
    "            parameter for Longformer\n",
    "        num_hidden_layers:\n",
    "            parameter for Longformer\n",
    "        attention_window:\n",
    "            parameter for Longformer\n",
    "        max_position_embeddings:\n",
    "            parameter for Longformer\n",
    "        replace_proba:\n",
    "            probability of masking transaction embedding\n",
    "        neg_count:\n",
    "            negative count for `QuerySoftmaxLoss`\n",
    "        log_logits:\n",
    "            if true than logits histogram will be logged. May be useful for `loss_temperature` tuning\n",
    "        encode_seq:\n",
    "            if true then outputs zero element of transformer i.e. encodes whole sequence. Else returns all outputs of transformer except 0th.\n",
    "        \"\"\"\n",
    " \n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(logger=False)\n",
    " \n",
    "        self.trx_encoder = trx_encoder\n",
    " \n",
    "        self.token_cls = torch.nn.Parameter(torch.randn(1, 1, hidden_size), requires_grad=True)\n",
    "        self.token_mask = torch.nn.Parameter(torch.randn(1, 1, hidden_size), requires_grad=True)\n",
    " \n",
    "        self.transf = LongformerModel(\n",
    "            config=LongformerConfig(\n",
    "                hidden_size=hidden_size,\n",
    "                num_attention_heads=num_attention_heads,\n",
    "                intermediate_size=intermediate_size,\n",
    "                num_hidden_layers=num_hidden_layers,\n",
    "                vocab_size=4,\n",
    "                max_position_embeddings=self.hparams.max_position_embeddings,\n",
    "                attention_window=attention_window,\n",
    "                hidden_dropout_prob=hidden_dropout_prob,\n",
    "                attention_probs_dropout_prob=attention_probs_dropout_prob\n",
    "            ),\n",
    "            add_pooling_layer=False,\n",
    "        )\n",
    "       \n",
    "        self.cpc_head1 = ContrastivePredictionHead(embeds_dim=hidden_size)\n",
    "        self.cpc_head2 = ContrastivePredictionHead(embeds_dim=hidden_size)\n",
    "       \n",
    "        self.mlm_loss = QuerySoftmaxLoss(temperature=loss_temperature, reduce=False)\n",
    "        self.cpc_loss = QuerySoftmaxLoss(temperature=loss_temperature, reduce=False)\n",
    "       \n",
    "        self.weight_mlm = weight_mlm\n",
    "        self.weight_cpc = weight_cpc\n",
    " \n",
    "        self.train_mlm_loss = MeanMetric(compute_on_step=False)\n",
    "        self.valid_mlm_loss = MeanMetric(compute_on_step=False)\n",
    "        \n",
    "        self.train_cpc_loss = MeanMetric(compute_on_step=False)\n",
    "        self.valid_cpc_loss = MeanMetric(compute_on_step=False)\n",
    " \n",
    "        \n",
    "        self.encode_seq = encode_seq\n",
    " \n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.Adam(self.parameters(),\n",
    "                                 lr=self.hparams.max_lr,\n",
    "                                 weight_decay=self.hparams.weight_decay,\n",
    "                                 )\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer=optim,\n",
    "            max_lr=self.hparams.max_lr,\n",
    "            total_steps=self.hparams.total_steps,\n",
    "            pct_start=self.hparams.pct_start,\n",
    "            anneal_strategy='cos',\n",
    "            cycle_momentum=False,\n",
    "            div_factor=25.0,\n",
    "            final_div_factor=10000.0,\n",
    "            three_phase=False,\n",
    "        )\n",
    "        scheduler = {'scheduler': scheduler, 'interval': 'step'}\n",
    "        return [optim], [scheduler]\n",
    " \n",
    "    def get_mask(self, attention_mask):\n",
    "        return torch.bernoulli(attention_mask.float() * self.hparams.replace_proba).bool()\n",
    " \n",
    "    def mask_x(self, x, attention_mask, mask):\n",
    "        shuffled_tokens = x[attention_mask.bool()]\n",
    "        B, T, H = x.size()\n",
    "        ix = torch.multinomial(torch.ones(shuffled_tokens.size(0)), B * T, replacement=True)\n",
    "        shuffled_tokens = shuffled_tokens[ix].view(B, T, H)\n",
    " \n",
    "        rand = torch.rand(B, T, device=x.device).unsqueeze(2).expand(B, T, H)\n",
    "        replace_to = torch.where(\n",
    "            rand < 0.8,\n",
    "            self.token_mask.expand_as(x),  # [MASK] token 80%\n",
    "            torch.where(\n",
    "                rand < 0.9,\n",
    "                shuffled_tokens,  # random token 90%\n",
    "                x,  # unchanged 10%\n",
    "            )\n",
    "        )\n",
    "        return torch.where(mask.bool().unsqueeze(2).expand_as(x), replace_to, x)\n",
    " \n",
    "    def forward(self, z: PaddedBatch):\n",
    "        z = self.trx_encoder(z)\n",
    "        \n",
    "        B, T, H = z.payload.size()\n",
    "        device = z.payload.device\n",
    " \n",
    "        if self.training:\n",
    "            start_pos = np.random.randint(0, self.hparams.max_position_embeddings - T - 1, 1)[0]\n",
    "        else:\n",
    "            start_pos = 0\n",
    " \n",
    "        inputs_embeds = z.payload\n",
    "        attention_mask = z.seq_len_mask.float()\n",
    " \n",
    "        inputs_embeds = torch.cat([\n",
    "            self.token_cls.expand(inputs_embeds.size(0), 1, H),\n",
    "            inputs_embeds,\n",
    "        ], dim=1)\n",
    "        attention_mask = torch.cat([\n",
    "            torch.ones(inputs_embeds.size(0), 1, device=device),\n",
    "            attention_mask,\n",
    "        ], dim=1)\n",
    "        position_ids = torch.arange(T + 1, device=z.device).view(1, -1).expand(B, T + 1) + start_pos\n",
    "        global_attention_mask = torch.cat([\n",
    "            torch.ones(inputs_embeds.size(0), 1, device=device),\n",
    "            torch.zeros(inputs_embeds.size(0), inputs_embeds.size(1) - 1, device=device),\n",
    "        ], dim=1)\n",
    " \n",
    "        out = self.transf(\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            global_attention_mask=global_attention_mask,\n",
    "        ).last_hidden_state\n",
    " \n",
    "        if self.hparams.norm_predict:\n",
    "            out = out / (out.pow(2).sum(dim=-1, keepdim=True) + 1e-9).pow(0.5)\n",
    "       \n",
    "        # CPC Predictions\n",
    "        cpc_preds1 = self.cpc_head1.forward(out[:, 0])\n",
    "        cpc_preds2 = self.cpc_head2.forward(out[:, 0])\n",
    "       \n",
    "        if self.encode_seq:\n",
    "            return out[:, 0]\n",
    "        else:\n",
    "            return PaddedBatch(out[:, 1:], z.seq_lens), [cpc_preds1, cpc_preds2]\n",
    " \n",
    "    def get_neg_ix(self, mask):\n",
    "        \"\"\"Sample from predicts, where `mask == True`, without self element.\n",
    "        sample from predicted tokens from batch\n",
    "        \"\"\"\n",
    "        mask_num = mask.int().sum()\n",
    "        mn = 1 - torch.eye(mask_num, device=mask.device)\n",
    "        neg_ix = torch.multinomial(mn, max(1, int(mn.shape[-1]*0.09)))  # self.hparams.neg_count\n",
    " \n",
    "        b_ix = torch.arange(mask.size(0), device=mask.device).view(-1, 1).expand_as(mask)[mask][neg_ix]\n",
    "        t_ix = torch.arange(mask.size(1), device=mask.device).view(1, -1).expand_as(mask)[mask][neg_ix]\n",
    "        return b_ix, t_ix\n",
    " \n",
    "    def loss_mlm_cpc(self, x: PaddedBatch, y: PaddedBatch, is_train_step):\n",
    "       \n",
    "        mask = self.get_mask(x.seq_len_mask)\n",
    "        masked_x = self.mask_x(x.payload, x.seq_len_mask, mask)\n",
    "        out, preds  = self.forward(PaddedBatch(masked_x, x.seq_lens))\n",
    "       \n",
    "        # MlM Part\n",
    "        out = out.payload\n",
    "        mask = mask\n",
    "        target = x.payload[mask].unsqueeze(1)  # N, 1, H\n",
    "        predict = out[mask].unsqueeze(1)  # N, 1, H\n",
    "        neg_ix = self.get_neg_ix(mask)\n",
    "        negative = out[neg_ix[0], neg_ix[1]]  # N, nneg, H\n",
    "        loss_mlm = self.mlm_loss(target, predict, negative)\n",
    " \n",
    "        if is_train_step and self.hparams.log_logits:\n",
    "            with torch.no_grad():\n",
    "                logits = self.mlm_loss.get_logits(target, predict, negative)\n",
    "            self.logger.experiment.add_histogram('mlm/logits',\n",
    "                                                 logits.flatten().detach(), self.global_step)\n",
    "           \n",
    "            \n",
    "        # CPC Part \n",
    "        targets, predicts, negatives = [], [], []\n",
    "        for i in range(2):\n",
    "            target = y.payload[:, i].unsqueeze(1)  # B, 1, H\n",
    "            predict = preds[i].unsqueeze(1)  # B, 1, H\n",
    " \n",
    "            # Sample negatives along batch_size dimension\n",
    "            batch_size = predict.size(0)\n",
    "            mn = 1 - torch.eye(batch_size, device=target.device)\n",
    "            neg_ix = torch.multinomial(mn, max(1, int(mn.shape[-1]*0.07)))  # self.hparams.neg_count\n",
    "            negative = preds[i][neg_ix, :]  # B, nneg, H\n",
    "            targets.append(target)\n",
    "            predicts.append(predict)\n",
    "            negatives.append(negative)\n",
    "       \n",
    "        targets = torch.concat(targets, dim=0)\n",
    "        predicts = torch.concat(predicts, dim=0)\n",
    "        negatives = torch.concat(negatives, dim=0)\n",
    "       \n",
    "        # Feed contrastive loss with negatives\n",
    "        loss_cpc = self.cpc_loss(targets, predicts, negatives) \n",
    "    \n",
    "        return loss_mlm, loss_cpc\n",
    " \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_trx, y_trx = batch\n",
    "       \n",
    "        z_trx = self.trx_encoder(x_trx)  # PB: B, T, H\n",
    "        y_trx = self.trx_encoder(y_trx)  #     B, 3, H\n",
    "        loss_mlm, loss_cpc = self.loss_mlm_cpc(z_trx, y_trx, is_train_step=True)\n",
    "        self.train_mlm_loss(loss_mlm)\n",
    "        self.train_cpc_loss(loss_cpc)\n",
    "        loss_mlm = loss_mlm.mean()\n",
    "        loss_cpc = loss_cpc.mean()\n",
    "        self.log(f'mlm/loss', loss_mlm)\n",
    "        self.log(f'cpc/loss', loss_cpc)\n",
    "        loss = self.weight_cpc*loss_cpc + self.weight_mlm*loss_mlm\n",
    "        return loss\n",
    " \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_trx, y_trx = batch\n",
    "        z_trx = self.trx_encoder(x_trx)  # PB: B, T, H\n",
    "        y_trx = self.trx_encoder(y_trx)\n",
    "        loss_mlm, loss_cpc = self.loss_mlm_cpc(z_trx, y_trx, is_train_step=False)\n",
    "        self.valid_cpc_loss(loss_cpc)\n",
    "        self.valid_mlm_loss(loss_mlm)\n",
    " \n",
    "    def training_epoch_end(self, _):\n",
    "        self.log(f'mlm/train_mlm_loss', self.train_mlm_loss, prog_bar=False)\n",
    "        self.log(f'cpc/train_cpc_loss', self.train_cpc_loss, prog_bar=False)\n",
    " \n",
    "    def validation_epoch_end(self, _):\n",
    "        self.log(f'mlm/valid_mlm_loss', self.valid_mlm_loss, prog_bar=True)\n",
    "        self.log(f'cpc/valid_cpc_loss', self.valid_cpc_loss, prog_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c266ef85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.seed:Global seed set to 80\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from functools import partial\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "from ptls.frames.supervised import SequenceToTarget\n",
    "from ptls.nn import Head\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "pl.seed_everything(80, workers=True)\n",
    "# torch.manual_seed(80)\n",
    "# random.seed(80)\n",
    "# np.random.seed(80)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9d3b52",
   "metadata": {},
   "source": [
    "# Supervised, no pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35d0ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ptls.nn import TrxEncoder, LongformerEncoder\n",
    "from ptls.frames.bert import MLMPretrainModule\n",
    "from ptls.nn import PBLinear, PBL2Norm, PBLayerNorm, PBDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d7ed9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trx_encoder_params = dict(\n",
    "    embeddings_noise=0,\n",
    "    numeric_values=numeric_values,\n",
    "    embeddings=embeddings,\n",
    "    emb_dropout=0.3,\n",
    "    spatial_dropout=False\n",
    ")\n",
    "\n",
    "trx_encoder = TrxEncoder(**trx_encoder_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe1d15f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alge/.local/share/virtualenvs/pytorch-lifestream-j3MrdFh4/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'trx_encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['trx_encoder'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "seq_encoder = MLMCPCPretrainModule(\n",
    "    trx_encoder=torch.nn.Sequential(\n",
    "        trx_encoder,\n",
    "        PBLinear(trx_encoder.output_size, 64),\n",
    "        PBDropout(0.2)\n",
    "    ),\n",
    "    hidden_size=64,\n",
    "    loss_temperature=20.0,\n",
    "\n",
    "    total_steps=30000,\n",
    "\n",
    "    replace_proba=0.1,\n",
    "    neg_count=64,\n",
    "\n",
    "    log_logits=False,\n",
    "    \n",
    "    encode_seq=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e53c7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alge/.local/share/virtualenvs/pytorch-lifestream-j3MrdFh4/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "downstream_model = SequenceToTarget(\n",
    "    seq_encoder=seq_encoder,\n",
    "    head=Head(\n",
    "        input_size=64,\n",
    "        hidden_layers_sizes=[32, 8],\n",
    "        drop_probs=[0.1, 0],\n",
    "        use_batch_norm=True,\n",
    "        objective='classification',\n",
    "        num_classes=2,\n",
    "    ),\n",
    "    loss=torch.nn.NLLLoss(),\n",
    "    metric_list=torchmetrics.AUROC(num_classes=2, compute_on_step=False),\n",
    "    pretrained_lr=0.001,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=2000, gamma=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b808c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.data_load.datasets import ParquetDataset, ParquetFiles\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter, FeatureFilter, ToTorch\n",
    "from ptls.frames.supervised.seq_to_target_dataset import SeqToTargetIterableDataset\n",
    "from ptls.data_load import IterableChain\n",
    "from ptls.frames import PtlsDataModule\n",
    "\n",
    "\n",
    "train_pq_files = ParquetFiles('./train.parquet/')\n",
    "valid_pq_files = ParquetFiles('./valid.parquet/')\n",
    "\n",
    "train_dataset = ParquetDataset(data_files=train_pq_files.data_files, shuffle_files=True)\n",
    "valid_dataset = ParquetDataset(data_files=valid_pq_files.data_files, shuffle_files=True)\n",
    "\n",
    "finetune_dm = PtlsDataModule(\n",
    "    train_data=SeqToTargetIterableDataset(train_dataset, target_col_name='flag'),\n",
    "    valid_data=SeqToTargetIterableDataset(valid_dataset, target_col_name='flag'),\n",
    "    train_num_workers=20,\n",
    "    train_batch_size=1024,\n",
    "    valid_batch_size=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20f9c2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True, used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(\n",
    "                save_dir='lightning_logs',\n",
    "                version='_super_no_pretrain_16_heads_2_layers_no_dropout_at_all_no_norm_emb_drop_0.3_PBDrop_0.2_no_transf_norm_FOLD1_plus_drop_in_head_0.1'\n",
    "            )\n",
    "\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=\"./ckpts/_super_no_pretrain_16_heads_2_layers_no_dropout_at_all_no_norm_emb_drop_0.3_PBDrop_0.2_no_transf_norm_FOLD1_plus_drop_in_head_0.1/\", save_top_k=40, mode='max', monitor=\"val_AUROC\")\n",
    "\n",
    "trainer_ft = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    gpus=1 if torch.cuda.is_available() else 0,\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    logger=logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ebeec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = _super_no_pretrain_16_heads_2_layers_no_dropout_at_all_no_norm_emb_drop_0.3_PBDrop_0.2_no_transf_norm_FOLD1_plus_drop_in_head_0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.gpu:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name          | Type                 | Params\n",
      "-------------------------------------------------------\n",
      "0 | seq_encoder   | MLMCPCPretrainModule | 420 K \n",
      "1 | head          | Head                 | 2.4 K \n",
      "2 | loss          | NLLLoss              | 0     \n",
      "3 | train_metrics | ModuleDict           | 0     \n",
      "4 | valid_metrics | ModuleDict           | 0     \n",
      "5 | test_metrics  | ModuleDict           | 0     \n",
      "-------------------------------------------------------\n",
      "422 K     Trainable params\n",
      "0         Non-trainable params\n",
      "422 K     Total params\n",
      "1.690     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4b7091afd041a79de7eb149e466de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alge/.local/share/virtualenvs/pytorch-lifestream-j3MrdFh4/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/alge/.local/share/virtualenvs/pytorch-lifestream-j3MrdFh4/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'logger.version = {trainer_ft.logger.version}')\n",
    "trainer_ft.fit(downstream_model, finetune_dm)\n",
    "print(trainer_ft.logged_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f27b889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93784264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37cdac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
