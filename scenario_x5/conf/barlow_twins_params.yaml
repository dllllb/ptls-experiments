data_module: 
  _target_: ptls.data_load.data_module.coles_data_module.ColesDataModuleTrain
  type: map
  setup: 
    col_id: client_id
    dataset_files: 
      data_path: ${hydra:runtime.cwd}/data/train_trx.parquet
    split_by: files
    valid_size: 0.05
    valid_split_seed: 42
  train: 
    min_seq_len: 30
    split_strategy: 
      split_strategy: SampleSlices
      split_count: 2
      cnt_min: 30
      cnt_max: 180
    augmentations: 
      - 
        - AllTimeShuffle
        - {}
      - 
        - DropoutTrx
        - 
          trx_dropout: 0.01
    num_workers: 8
    batch_size: 256
  valid: 
    split_strategy: 
      split_strategy: SampleSlices
      split_count: 2
      cnt_min: 30
      cnt_max: 180
    augmentations: []
    num_workers: 16
    batch_size: 256

seed_everything: 42

trainer: 
  gpus: 1
  auto_select_gpus: false
  max_epochs: 45
  enable_checkpointing: false
  deterministic: true

logger_name: barlow_twins_model

pl_module:
  _target_: ptls.frames.coles.CoLESModule
  validation_metric:
    _target_: ptls.frames.coles.metric.BatchRecallTopK
    K: 1
    metric: cosine
  seq_encoder:
    _target_: ptls.nn.RnnSeqEncoder
    trx_encoder: 
      _target_: ptls.nn.TrxEncoder
      norm_embeddings: false
      embeddings_noise: 0.003
      embeddings: 
        level_3: 
          in: 200
          out: 16
        level_4: 
          in: 800
          out: 16
        segment_id: 
          in: 120
          out: 16
      numeric_values: 
        trn_sum_from_iss: identity
        netto: identity
        regular_points_received: identity
    type: gru
    hidden_size: 800
    bidir: false
    trainable_starter: static
  head:
    _target_: ptls.nn.Head
    input_size: ${pl_module.seq_encoder.hidden_size}
    hidden_layers_sizes: [256, 256]
    use_batch_norm: true
  lr_scheduler_partial:
    _partial_: true
    _target_: torch.optim.lr_scheduler.StepLR
    step_size: 3
    gamma: 0.9025
  loss:
    _target_: ptls.frames.coles.losses.BarlowTwinsLoss
    lambd: 0.04
  optimizer_partial:
    _partial_: true
    _target_: torch.optim.Adam
    lr: 0.002
    weight_decay: 0.0
  norm_scores: false

model_path: models/barlow_twins_model.p

inference_dataloader: 
  col_id: client_id
  dataset_files: 
    - ${hydra:runtime.cwd}/data/train_trx.parquet
    - ${hydra:runtime.cwd}/data/test_trx.parquet
  SeqLenLimit: 
    max_seq_len: 800
  loader: 
    num_workers: 4
    batch_size: 1000

output: 
  path: ${hydra:runtime.cwd}/data/barlow_twins_embeddings
  format: pickle
