defaults:
  - _self_
  - inference/default
  - inference/seq_encoder/pretrained

seed_everything: 42
logger_name: rtd_model
model_path: models/rtd_model.p
embed_file_name: rtd_embeddings

data_module:
  _target_: ptls.data_load.data_module.rtd_data_module.RtdDataModuleTrain
  type: map
  setup: 
    col_id: customer_id
    dataset_files: 
      data_path: ${hydra:runtime.cwd}/data/train_trx.parquet
    split_by: files
    valid_size: 0.05
    valid_split_seed: 42
  train: 
    min_seq_len: 25
    augmentations: 
      - 
        - DropoutTrx
        - 
          trx_dropout: 0.01
      - 
        - SeqLenLimit
        - 
          max_seq_len: 1200
    num_workers: 8
    batch_size: 128
  valid: 
    augmentations: 
      - 
        - SeqLenLimit
        - 
          max_seq_len: 1200
    num_workers: 16
    batch_size: 1024
  replace_token: 
    replace_prob: 0.15
    skip_first: 1

trainer: 
  gpus: 1
  auto_select_gpus: false
  max_epochs: 100
  deterministic: true

pl_module:
  _target_: ptls.frames.bert.RtdModule
  seq_encoder:
    _target_: ptls.nn.RnnSeqEncoder
    trx_encoder: 
      _target_: ptls.nn.TrxEncoder
      norm_embeddings: false
      embeddings_noise: 0.003
      embeddings: 
        mcc_code: 
          in: 200
          out: 48
        tr_type: 
          in: 100
          out: 24
      numeric_values: 
        amount: identity
    type: gru
    hidden_size: 256
    bidir: false
    trainable_starter: static
  lr_scheduler_partial:
    _partial_: true
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    mode: max
    patience: 15
    threshold: 0.001
    min_lr: 1e-6
    verbose: true
  optimizer_partial:
    _partial_: true
    _target_: torch.optim.Adam
    lr: 0.001
    weight_decay: 0.0
