{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb70eaa-73aa-4f21-b44b-d18fe49c2df2",
   "metadata": {},
   "source": [
    "# CoLES updated\n",
    "\n",
    "CoLES with numeric preprocing via normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be09b619-0576-4693-8a9f-c7dfe1e2a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08fce4c6-4133-4498-ab86-94207d18d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.preprocessing import PandasDataPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15d23f98-e5de-4615-ade3-bd2031695455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "574b7060-4db2-43d3-a70c-be23ae978a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ptls.data_load\n",
    "import ptls.data_load.datasets\n",
    "import ptls.frames\n",
    "import ptls.frames.coles\n",
    "import ptls.frames.inference_module\n",
    "import ptls.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3363116-5aa9-43f8-97f4-b2b0845d80b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f1d76c2-175c-4366-8098-98a63dac153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "357dc0a7-1801-4c76-adea-ffe692df7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb031d2-992e-4769-958a-bf5653b45a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c15e721-b217-4b30-aec1-473ff834b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1dafb0-48d3-4d02-aff4-e94ac02bbfec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a40fc95f-a6cc-43b2-9e19-a31c73ce0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm(df):\n",
    "    values = torch.cat(df['amount_rur'].values.tolist())\n",
    "    values = values.sign() * values.abs().log1p()\n",
    "    m = values.mean().item()\n",
    "    s = values.std().item()\n",
    "    return m, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4db9be61-1ac4-456e-817d-85a20be19735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogScaler(ptls.nn.trx_encoder.scalers.IdentityScaler):\n",
    "    def __init__(self, m, s):\n",
    "        super().__init__()\n",
    "        self.m = m\n",
    "        self.s = s\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = super().forward(x)\n",
    "        return (x.abs().log1p() * x.sign() - self.m) / self.s\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ff32a-f11f-4246-92f4-fbae33cce9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f732af-4514-4c30-aa7b-8ec6ddd992f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain_logger_version = 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type            | Params\n",
      "-------------------------------------------------------\n",
      "0 | _loss              | ContrastiveLoss | 0     \n",
      "1 | _seq_encoder       | Sequential      | 2.0 M \n",
      "2 | _validation_metric | BatchRecallTopK | 0     \n",
      "3 | _head              | Head            | 0     \n",
      "-------------------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "8.061     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME='04_coles'\n",
    "\n",
    "for fold_i in [0, 1, 2, 3, 4]:\n",
    "\n",
    "    df_trx_pretrain = pd.read_pickle(f'data/fold_{fold_i}/df_trx_pretrain.pickle')\n",
    "    df_seq_pretrain = pd.read_pickle(f'data/fold_{fold_i}/df_seq_pretrain.pickle')\n",
    "    df_gbm_train = pd.read_pickle(f'data/fold_{fold_i}/df_gbm_train.pickle')\n",
    "    df_gbm_test = pd.read_pickle(f'data/fold_{fold_i}/df_gbm_test.pickle')\n",
    "\n",
    "    with open(f'data/fold_{fold_i}/pdp.pickle', 'rb') as f:\n",
    "        pdp = pickle.load(f)\n",
    "        \n",
    "\n",
    "    df_seq_pretrain_train, df_seq_pretrain_valid = train_test_split(\n",
    "        df_seq_pretrain, test_size=0.05, shuffle=True, random_state=42)\n",
    "\n",
    "    len(df_seq_pretrain_train), len(df_seq_pretrain_valid)\n",
    "\n",
    "    coles_data_module = ptls.frames.PtlsDataModule(\n",
    "        train_data=ptls.frames.coles.ColesDataset(\n",
    "            data=ptls.data_load.datasets.MemoryMapDataset(\n",
    "                df_seq_pretrain_train.to_dict(orient='records') + \n",
    "                df_trx_pretrain.to_dict(orient='records')\n",
    "            ),\n",
    "            splitter=ptls.frames.coles.split_strategy.SampleSlices(\n",
    "                split_count=5,\n",
    "                cnt_min=25,\n",
    "                cnt_max=200,\n",
    "            ),\n",
    "        ),\n",
    "        valid_data=ptls.frames.coles.ColesDataset(\n",
    "            data=ptls.data_load.datasets.MemoryMapDataset(\n",
    "                df_seq_pretrain_train.to_dict(orient='records')),\n",
    "            splitter=ptls.frames.coles.split_strategy.SampleSlices(\n",
    "                split_count=5,\n",
    "                cnt_min=25,\n",
    "                cnt_max=100,\n",
    "            ),\n",
    "        ),\n",
    "        train_batch_size=64,\n",
    "        train_num_workers=4,\n",
    "        valid_batch_size=650,\n",
    "    )\n",
    "\n",
    "    pl_coles_module = ptls.frames.coles.CoLESModule(\n",
    "        validation_metric=ptls.frames.coles.metric.BatchRecallTopK(\n",
    "            K=4,\n",
    "            metric='cosine',\n",
    "        ),\n",
    "        seq_encoder=torch.nn.Sequential(\n",
    "            ptls.nn.TrxEncoder(\n",
    "                norm_embeddings=False,\n",
    "                embeddings_noise=0.003,\n",
    "                use_batch_norm=False,\n",
    "                embeddings={\n",
    "                    'weekday': {'in': 10, 'out': 8},\n",
    "                    'small_group': {'in': 250, 'out': 16},\n",
    "                    'event_time': {'in': 800, 'out': 8},\n",
    "                },\n",
    "                numeric_values={ \n",
    "                    # 'amount_rur': 'identity',\n",
    "                    # 'amount_rur': 'log',\n",
    "                    'amount_rur': LogScaler(*get_norm(df_seq_pretrain_train)),\n",
    "                },\n",
    "            ),\n",
    "            ptls.nn.RnnEncoder(\n",
    "                # input_size=25,\n",
    "                input_size=33,\n",
    "                type='gru',\n",
    "                hidden_size=800,\n",
    "                is_reduce_sequence=True,\n",
    "            ),\n",
    "        ),\n",
    "        head=ptls.nn.Head(use_norm_encoder=True),\n",
    "        loss=ptls.frames.coles.losses.ContrastiveLoss(\n",
    "            margin=0.5,\n",
    "            sampling_strategy=ptls.frames.coles.sampling_strategies.HardNegativePairSelector(\n",
    "              neg_count=5,\n",
    "            ),\n",
    "        ),\n",
    "        # loss=ptls.frames.coles.losses.SoftmaxLoss(\n",
    "        #     temperature=0.05,\n",
    "        # ),\n",
    "        optimizer_partial=partial(torch.optim.Adam, lr=0.001, weight_decay=0.0),\n",
    "        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=30, gamma=0.9025)\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=1,\n",
    "        max_epochs=150, # 150,\n",
    "        enable_checkpointing=False,\n",
    "        enable_progress_bar=False,\n",
    "        gradient_clip_val=0.5,\n",
    "        gradient_clip_algorithm=\"value\",    \n",
    "    )   \n",
    "\n",
    "    pretrain_logger_version = trainer.logger.version\n",
    "    print(f'pretrain_logger_version = {pretrain_logger_version}')\n",
    "    trainer.fit(pl_coles_module, coles_data_module)\n",
    "\n",
    "    inference_dl_gbm_train = torch.utils.data.DataLoader(\n",
    "        dataset=ptls.data_load.datasets.MemoryMapDataset(\n",
    "            df_gbm_train.to_dict(orient='records'),\n",
    "            i_filters=[\n",
    "                ptls.data_load.iterable_processing.ISeqLenLimit(max_seq_len=2000), \n",
    "            ],\n",
    "        ),\n",
    "        collate_fn=ptls.data_load.utils.collate_feature_dict,\n",
    "        shuffle=False,\n",
    "        batch_size=1000,\n",
    "        num_workers=12,\n",
    "    )\n",
    "\n",
    "    inference_dl_gbm_test = torch.utils.data.DataLoader(\n",
    "        dataset=ptls.data_load.datasets.MemoryMapDataset(\n",
    "            df_gbm_test.to_dict(orient='records'),\n",
    "            i_filters=[\n",
    "                ptls.data_load.iterable_processing.ISeqLenLimit(max_seq_len=2000), \n",
    "            ],\n",
    "        ),\n",
    "        collate_fn=ptls.data_load.utils.collate_feature_dict,\n",
    "        shuffle=False,\n",
    "        batch_size=1000,\n",
    "        num_workers=12,\n",
    "    )\n",
    "\n",
    "    inf_model = ptls.frames.inference_module.InferenceModule(\n",
    "        model=pl_coles_module.seq_encoder, pandas_output=True, model_out_name='emb')\n",
    "\n",
    "    predict_gbm_train = pl.Trainer(gpus=1, enable_progress_bar=False, logger=None)\\\n",
    "    .predict(inf_model, inference_dl_gbm_train)\n",
    "\n",
    "    predict_gbm_test = pl.Trainer(gpus=1, enable_progress_bar=False, logger=None)\\\n",
    "    .predict(inf_model, inference_dl_gbm_test)\n",
    "\n",
    "    predict_gbm_train = pd.concat(predict_gbm_train, axis=0)\n",
    "\n",
    "    predict_gbm_test = pd.concat(predict_gbm_test, axis=0)\n",
    "\n",
    "    predict_gbm_train.set_index('client_id', inplace=True)\n",
    "    predict_gbm_test.set_index('client_id', inplace=True)\n",
    "\n",
    "    gbm_model = LGBMClassifier(**{\n",
    "          'n_estimators': 1000,\n",
    "          'boosting_type': 'gbdt',\n",
    "          'objective': 'multiclass',\n",
    "          'num_class': 4,\n",
    "          'metric': 'multi_error',\n",
    "          'learning_rate': 0.02,\n",
    "          'subsample': 0.75,\n",
    "          'subsample_freq': 1,\n",
    "          'feature_fraction': 0.75,\n",
    "          'colsample_bytree': None,\n",
    "          'max_depth': 12,\n",
    "          'lambda_l1': 1,\n",
    "          'reg_alpha': None,\n",
    "          'lambda_l2': 1,\n",
    "          'reg_lambda': None,\n",
    "          'min_data_in_leaf': 50,\n",
    "          'min_child_samples': None,\n",
    "          'num_leaves': 50,\n",
    "          'random_state': 42,\n",
    "          'n_jobs': 4,\n",
    "    })\n",
    "\n",
    "    gbm_model.fit(predict_gbm_train.drop(columns='bins'), predict_gbm_train['bins'])\n",
    "\n",
    "    acc = accuracy_score(\n",
    "        gbm_model.predict(predict_gbm_test.drop(columns='bins')), \n",
    "        predict_gbm_test['bins'],\n",
    "    )\n",
    "    acc\n",
    "\n",
    "    with open('results.log', 'at') as f:\n",
    "        print('\\t'.join([\n",
    "            MODEL_NAME,\n",
    "            f'{datetime.datetime.now():%Y-%m-%d %H:%M:%S}',\n",
    "            f'{fold_i}',\n",
    "            'accuracy',\n",
    "            f'{acc:.4f}',\n",
    "            f'{pretrain_logger_version}',\n",
    "    ]), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284724a0-6e8f-482a-a5ea-d06aa19d9196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d115b2b-f81d-4475-85f0-26cbf8020857",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.read_csv(\n",
    "    # 'results.log',\n",
    "    'results.log',\n",
    "    sep='\\t', header=None,\n",
    "    names=['model', 'time', 'fold_i', 'metric', 'value', 'pretrain_logger_version']\n",
    ")\n",
    "df_res.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c31661-f5f2-49ff-8cdf-8fb1c697498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.groupby('model')['value'].agg(['mean', 'std', lambda x: sorted(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e17723-beac-43bc-81f3-6ed5040adb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23e1826-d0b5-43ed-a2a7-442772b9141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 1, figsize=(16, 4))\n",
    "sns.boxplot(\n",
    "    data=df_res[lambda x: ~x['model'].isin(['02_coles_0'])],\n",
    "    x='model',\n",
    "    y='value',\n",
    ")\n",
    "sns.scatterplot(\n",
    "    data=df_res[lambda x: ~x['model'].isin(['02_coles_0'])],\n",
    "    x='model',\n",
    "    y='value',\n",
    "    marker=\"x\",\n",
    "    c='k',\n",
    "    s=150,\n",
    ")\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d4af1-ac00-4e8e-8f33-1265a35e3e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "df_res.pivot(\n",
    "    index='model', columns='fold_i', values='value')\\\n",
    ".loc[['02_agg_baseline', '02_coles_100', '02_coles_orig', '02_coles_250']]\\\n",
    ".plot(ax=ax, marker='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f37a751-4468-4b9c-bf31-8bb5620f9032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c278eae6-51a1-4348-9c71-ce3e73f264f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptls-experiments",
   "language": "python",
   "name": "ptls-experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
